{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5591ffee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.nn.modules.pooling import AdaptiveAvgPool2d\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "import torchvision.models as models\n",
    "import torchvision\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import math\n",
    "\n",
    "import cv2\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import abc  # For implementing abstract methods\n",
    "\n",
    "import CAM.cam\n",
    "from utils import load_model, load_data, train_cam_models, test_cam_models,  informacion_umbral_mascaras\n",
    "from CAM.utils_cam import plot_grid\n",
    "import json\n",
    "import math\n",
    "from torchvision.transforms import Resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c549825",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\pedro/.cache\\torch\\hub\\NVIDIA_DeepLearningExamples_torchhub\n",
      "C:\\Users\\pedro/.cache\\torch\\hub\\NVIDIA_DeepLearningExamples_torchhub\\PyTorch\\Classification\\ConvNets\\image_classification\\models\\common.py:13: UserWarning: pytorch_quantization module not found, quantization will not be available\n",
      "  warnings.warn(\n",
      "C:\\Users\\pedro/.cache\\torch\\hub\\NVIDIA_DeepLearningExamples_torchhub\\PyTorch\\Classification\\ConvNets\\image_classification\\models\\efficientnet.py:17: UserWarning: pytorch_quantization module not found, quantization will not be available\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE:  cuda:0\n",
      "Clases:  ['Benign', 'Pathological']\n",
      "Train image size: 11454\n",
      "Validation image size: 2862\n",
      "Test image size: 7336\n",
      "Dataset loaded.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DEVICE:  cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\pedro/.cache\\torch\\hub\\NVIDIA_DeepLearningExamples_torchhub\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases:  ['Benign', 'Pathological']\n",
      "Train image size: 11454\n",
      "Validation image size: 2862\n",
      "Test image size: 7336\n",
      "Dataset loaded.\n",
      "\n",
      "\n",
      " CAM\n",
      "model_vgg-cam not found\n",
      "Epoch 1/4\n",
      "----------\n",
      "[VGG-cam]. Epoch [1/4], Batch[72/1431] loss: 0.061\n",
      "[VGG-cam]. Epoch [1/4], Batch[144/1431] loss: 0.049\n",
      "[VGG-cam]. Epoch [1/4], Batch[216/1431] loss: 0.044\n",
      "[VGG-cam]. Epoch [1/4], Batch[288/1431] loss: 0.041\n",
      "[VGG-cam]. Epoch [1/4], Batch[360/1431] loss: 0.039\n",
      "[VGG-cam]. Epoch [1/4], Batch[432/1431] loss: 0.037\n",
      "[VGG-cam]. Epoch [1/4], Batch[504/1431] loss: 0.035\n",
      "[VGG-cam]. Epoch [1/4], Batch[576/1431] loss: 0.034\n",
      "[VGG-cam]. Epoch [1/4], Batch[648/1431] loss: 0.033\n",
      "[VGG-cam]. Epoch [1/4], Batch[720/1431] loss: 0.031\n",
      "[VGG-cam]. Epoch [1/4], Batch[792/1431] loss: 0.030\n",
      "[VGG-cam]. Epoch [1/4], Batch[864/1431] loss: 0.029\n",
      "[VGG-cam]. Epoch [1/4], Batch[936/1431] loss: 0.028\n",
      "[VGG-cam]. Epoch [1/4], Batch[1008/1431] loss: 0.027\n",
      "[VGG-cam]. Epoch [1/4], Batch[1080/1431] loss: 0.027\n",
      "[VGG-cam]. Epoch [1/4], Batch[1152/1431] loss: 0.026\n",
      "[VGG-cam]. Epoch [1/4], Batch[1224/1431] loss: 0.026\n",
      "[VGG-cam]. Epoch [1/4], Batch[1296/1431] loss: 0.025\n",
      "[VGG-cam]. Epoch [1/4], Batch[1368/1431] loss: 0.025\n",
      "train Loss: 0.0246 Acc: 0.9254\n",
      "\n",
      "[VGG-cam]. Epoch [1/4], Batch[143/2862] loss: 0.004\n",
      "[VGG-cam]. Epoch [1/4], Batch[286/2862] loss: 0.014\n",
      "[VGG-cam]. Epoch [1/4], Batch[429/2862] loss: 0.016\n",
      "[VGG-cam]. Epoch [1/4], Batch[572/2862] loss: 0.013\n",
      "[VGG-cam]. Epoch [1/4], Batch[715/2862] loss: 0.012\n",
      "[VGG-cam]. Epoch [1/4], Batch[858/2862] loss: 0.011\n",
      "[VGG-cam]. Epoch [1/4], Batch[1001/2862] loss: 0.010\n",
      "[VGG-cam]. Epoch [1/4], Batch[1144/2862] loss: 0.011\n",
      "[VGG-cam]. Epoch [1/4], Batch[1287/2862] loss: 0.011\n",
      "[VGG-cam]. Epoch [1/4], Batch[1430/2862] loss: 0.011\n",
      "[VGG-cam]. Epoch [1/4], Batch[1573/2862] loss: 0.011\n",
      "[VGG-cam]. Epoch [1/4], Batch[1716/2862] loss: 0.011\n",
      "[VGG-cam]. Epoch [1/4], Batch[1859/2862] loss: 0.011\n",
      "[VGG-cam]. Epoch [1/4], Batch[2002/2862] loss: 0.011\n",
      "[VGG-cam]. Epoch [1/4], Batch[2145/2862] loss: 0.011\n",
      "[VGG-cam]. Epoch [1/4], Batch[2288/2862] loss: 0.012\n",
      "[VGG-cam]. Epoch [1/4], Batch[2431/2862] loss: 0.045\n",
      "[VGG-cam]. Epoch [1/4], Batch[2574/2862] loss: 0.055\n",
      "[VGG-cam]. Epoch [1/4], Batch[2717/2862] loss: 0.070\n",
      "[VGG-cam]. Epoch [1/4], Batch[2860/2862] loss: 0.092\n",
      "[VGG-cam]. Epoch [1/4], Batch[2861/2862] loss: 0.092\n",
      "val Loss: 0.0916 Acc: 0.9626\n",
      "New best model found!\n",
      "New record loss: 0.09163845668246588, previous record loss: inf\n",
      "técnica:  cam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pedro\\Documents\\TFG\\TFG\\src\\CAM\\cam_abstract.py:131: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matricesor `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at  C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\TensorShape.cpp:2318.)\n",
      "  activations_final = relu(((parameters[class_i]*activations.T).T).sum(axis=0)).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LONGITUD DEL HEATMAPS:  447\n",
      "Técnica:  cam\n",
      "\n",
      "Epoch 2/4\n",
      "----------\n",
      "[VGG-cam]. Epoch [2/4], Batch[72/1431] loss: 0.013\n",
      "[VGG-cam]. Epoch [2/4], Batch[144/1431] loss: 0.012\n",
      "[VGG-cam]. Epoch [2/4], Batch[216/1431] loss: 0.013\n",
      "[VGG-cam]. Epoch [2/4], Batch[288/1431] loss: 0.014\n",
      "[VGG-cam]. Epoch [2/4], Batch[360/1431] loss: 0.013\n",
      "[VGG-cam]. Epoch [2/4], Batch[432/1431] loss: 0.012\n",
      "[VGG-cam]. Epoch [2/4], Batch[504/1431] loss: 0.012\n",
      "[VGG-cam]. Epoch [2/4], Batch[576/1431] loss: 0.012\n",
      "[VGG-cam]. Epoch [2/4], Batch[648/1431] loss: 0.012\n",
      "[VGG-cam]. Epoch [2/4], Batch[720/1431] loss: 0.012\n",
      "[VGG-cam]. Epoch [2/4], Batch[792/1431] loss: 0.012\n",
      "[VGG-cam]. Epoch [2/4], Batch[864/1431] loss: 0.012\n",
      "[VGG-cam]. Epoch [2/4], Batch[936/1431] loss: 0.012\n",
      "[VGG-cam]. Epoch [2/4], Batch[1008/1431] loss: 0.012\n",
      "[VGG-cam]. Epoch [2/4], Batch[1080/1431] loss: 0.012\n",
      "[VGG-cam]. Epoch [2/4], Batch[1152/1431] loss: 0.012\n",
      "[VGG-cam]. Epoch [2/4], Batch[1224/1431] loss: 0.012\n",
      "[VGG-cam]. Epoch [2/4], Batch[1296/1431] loss: 0.013\n",
      "[VGG-cam]. Epoch [2/4], Batch[1368/1431] loss: 0.012\n",
      "train Loss: 0.0122 Acc: 0.9665\n",
      "\n",
      "[VGG-cam]. Epoch [2/4], Batch[143/2862] loss: 0.002\n",
      "[VGG-cam]. Epoch [2/4], Batch[286/2862] loss: 0.014\n",
      "[VGG-cam]. Epoch [2/4], Batch[429/2862] loss: 0.024\n",
      "[VGG-cam]. Epoch [2/4], Batch[572/2862] loss: 0.019\n",
      "[VGG-cam]. Epoch [2/4], Batch[715/2862] loss: 0.017\n",
      "[VGG-cam]. Epoch [2/4], Batch[858/2862] loss: 0.014\n",
      "[VGG-cam]. Epoch [2/4], Batch[1001/2862] loss: 0.013\n",
      "[VGG-cam]. Epoch [2/4], Batch[1144/2862] loss: 0.015\n",
      "[VGG-cam]. Epoch [2/4], Batch[1287/2862] loss: 0.013\n",
      "[VGG-cam]. Epoch [2/4], Batch[1430/2862] loss: 0.012\n",
      "[VGG-cam]. Epoch [2/4], Batch[1573/2862] loss: 0.012\n",
      "[VGG-cam]. Epoch [2/4], Batch[1716/2862] loss: 0.012\n",
      "[VGG-cam]. Epoch [2/4], Batch[1859/2862] loss: 0.013\n",
      "[VGG-cam]. Epoch [2/4], Batch[2002/2862] loss: 0.012\n",
      "[VGG-cam]. Epoch [2/4], Batch[2145/2862] loss: 0.013\n",
      "[VGG-cam]. Epoch [2/4], Batch[2288/2862] loss: 0.014\n",
      "[VGG-cam]. Epoch [2/4], Batch[2431/2862] loss: 0.031\n",
      "[VGG-cam]. Epoch [2/4], Batch[2574/2862] loss: 0.033\n",
      "[VGG-cam]. Epoch [2/4], Batch[2717/2862] loss: 0.046\n",
      "[VGG-cam]. Epoch [2/4], Batch[2860/2862] loss: 0.058\n",
      "[VGG-cam]. Epoch [2/4], Batch[2861/2862] loss: 0.058\n",
      "val Loss: 0.0575 Acc: 0.9794\n",
      "New best model found!\n",
      "New record loss: 0.05753357865959815, previous record loss: 0.09163845668246588\n",
      "técnica:  cam\n",
      "LONGITUD DEL HEATMAPS:  447\n",
      "Técnica:  cam\n",
      "\n",
      "Epoch 3/4\n",
      "----------\n",
      "[VGG-cam]. Epoch [3/4], Batch[72/1431] loss: 0.008\n",
      "[VGG-cam]. Epoch [3/4], Batch[144/1431] loss: 0.008\n",
      "[VGG-cam]. Epoch [3/4], Batch[216/1431] loss: 0.008\n",
      "[VGG-cam]. Epoch [3/4], Batch[288/1431] loss: 0.009\n",
      "[VGG-cam]. Epoch [3/4], Batch[360/1431] loss: 0.008\n",
      "[VGG-cam]. Epoch [3/4], Batch[432/1431] loss: 0.009\n",
      "[VGG-cam]. Epoch [3/4], Batch[504/1431] loss: 0.008\n",
      "[VGG-cam]. Epoch [3/4], Batch[576/1431] loss: 0.008\n",
      "[VGG-cam]. Epoch [3/4], Batch[648/1431] loss: 0.008\n",
      "[VGG-cam]. Epoch [3/4], Batch[720/1431] loss: 0.008\n",
      "[VGG-cam]. Epoch [3/4], Batch[792/1431] loss: 0.007\n",
      "[VGG-cam]. Epoch [3/4], Batch[864/1431] loss: 0.008\n",
      "[VGG-cam]. Epoch [3/4], Batch[936/1431] loss: 0.008\n",
      "[VGG-cam]. Epoch [3/4], Batch[1008/1431] loss: 0.008\n",
      "[VGG-cam]. Epoch [3/4], Batch[1080/1431] loss: 0.008\n",
      "[VGG-cam]. Epoch [3/4], Batch[1152/1431] loss: 0.008\n",
      "[VGG-cam]. Epoch [3/4], Batch[1224/1431] loss: 0.008\n",
      "[VGG-cam]. Epoch [3/4], Batch[1296/1431] loss: 0.008\n",
      "[VGG-cam]. Epoch [3/4], Batch[1368/1431] loss: 0.008\n",
      "train Loss: 0.0076 Acc: 0.9804\n",
      "\n",
      "[VGG-cam]. Epoch [3/4], Batch[143/2862] loss: 0.103\n",
      "[VGG-cam]. Epoch [3/4], Batch[286/2862] loss: 0.254\n",
      "[VGG-cam]. Epoch [3/4], Batch[429/2862] loss: 0.375\n",
      "[VGG-cam]. Epoch [3/4], Batch[572/2862] loss: 0.297\n",
      "[VGG-cam]. Epoch [3/4], Batch[715/2862] loss: 0.259\n",
      "[VGG-cam]. Epoch [3/4], Batch[858/2862] loss: 0.218\n",
      "[VGG-cam]. Epoch [3/4], Batch[1001/2862] loss: 0.197\n",
      "[VGG-cam]. Epoch [3/4], Batch[1144/2862] loss: 0.198\n",
      "[VGG-cam]. Epoch [3/4], Batch[1287/2862] loss: 0.194\n",
      "[VGG-cam]. Epoch [3/4], Batch[1430/2862] loss: 0.193\n",
      "[VGG-cam]. Epoch [3/4], Batch[1573/2862] loss: 0.205\n",
      "[VGG-cam]. Epoch [3/4], Batch[1716/2862] loss: 0.196\n",
      "[VGG-cam]. Epoch [3/4], Batch[1859/2862] loss: 0.204\n",
      "[VGG-cam]. Epoch [3/4], Batch[2002/2862] loss: 0.206\n",
      "[VGG-cam]. Epoch [3/4], Batch[2145/2862] loss: 0.200\n",
      "[VGG-cam]. Epoch [3/4], Batch[2288/2862] loss: 0.194\n",
      "[VGG-cam]. Epoch [3/4], Batch[2431/2862] loss: 0.184\n",
      "[VGG-cam]. Epoch [3/4], Batch[2574/2862] loss: 0.174\n",
      "[VGG-cam]. Epoch [3/4], Batch[2717/2862] loss: 0.166\n",
      "[VGG-cam]. Epoch [3/4], Batch[2860/2862] loss: 0.158\n",
      "[VGG-cam]. Epoch [3/4], Batch[2861/2862] loss: 0.158\n",
      "val Loss: 0.1575 Acc: 0.9507\n",
      "\n",
      "Epoch 4/4\n",
      "----------\n",
      "[VGG-cam]. Epoch [4/4], Batch[72/1431] loss: 0.013\n",
      "[VGG-cam]. Epoch [4/4], Batch[144/1431] loss: 0.008\n",
      "[VGG-cam]. Epoch [4/4], Batch[216/1431] loss: 0.007\n",
      "[VGG-cam]. Epoch [4/4], Batch[288/1431] loss: 0.007\n",
      "[VGG-cam]. Epoch [4/4], Batch[360/1431] loss: 0.007\n",
      "[VGG-cam]. Epoch [4/4], Batch[432/1431] loss: 0.007\n",
      "[VGG-cam]. Epoch [4/4], Batch[504/1431] loss: 0.006\n",
      "[VGG-cam]. Epoch [4/4], Batch[576/1431] loss: 0.006\n",
      "[VGG-cam]. Epoch [4/4], Batch[648/1431] loss: 0.006\n",
      "[VGG-cam]. Epoch [4/4], Batch[720/1431] loss: 0.005\n",
      "[VGG-cam]. Epoch [4/4], Batch[792/1431] loss: 0.005\n",
      "[VGG-cam]. Epoch [4/4], Batch[864/1431] loss: 0.005\n",
      "[VGG-cam]. Epoch [4/4], Batch[936/1431] loss: 0.006\n",
      "[VGG-cam]. Epoch [4/4], Batch[1008/1431] loss: 0.006\n",
      "[VGG-cam]. Epoch [4/4], Batch[1080/1431] loss: 0.005\n",
      "[VGG-cam]. Epoch [4/4], Batch[1152/1431] loss: 0.005\n",
      "[VGG-cam]. Epoch [4/4], Batch[1224/1431] loss: 0.005\n",
      "[VGG-cam]. Epoch [4/4], Batch[1296/1431] loss: 0.006\n",
      "[VGG-cam]. Epoch [4/4], Batch[1368/1431] loss: 0.006\n",
      "train Loss: 0.0060 Acc: 0.9848\n",
      "\n",
      "[VGG-cam]. Epoch [4/4], Batch[143/2862] loss: 0.125\n",
      "[VGG-cam]. Epoch [4/4], Batch[286/2862] loss: 0.190\n",
      "[VGG-cam]. Epoch [4/4], Batch[429/2862] loss: 0.249\n",
      "[VGG-cam]. Epoch [4/4], Batch[572/2862] loss: 0.242\n",
      "[VGG-cam]. Epoch [4/4], Batch[715/2862] loss: 0.220\n",
      "[VGG-cam]. Epoch [4/4], Batch[858/2862] loss: 0.226\n",
      "[VGG-cam]. Epoch [4/4], Batch[1001/2862] loss: 0.244\n",
      "[VGG-cam]. Epoch [4/4], Batch[1144/2862] loss: 0.238\n",
      "[VGG-cam]. Epoch [4/4], Batch[1287/2862] loss: 0.230\n",
      "[VGG-cam]. Epoch [4/4], Batch[1430/2862] loss: 0.235\n",
      "[VGG-cam]. Epoch [4/4], Batch[1573/2862] loss: 0.239\n",
      "[VGG-cam]. Epoch [4/4], Batch[1716/2862] loss: 0.248\n",
      "[VGG-cam]. Epoch [4/4], Batch[1859/2862] loss: 0.261\n",
      "[VGG-cam]. Epoch [4/4], Batch[2002/2862] loss: 0.266\n",
      "[VGG-cam]. Epoch [4/4], Batch[2145/2862] loss: 0.265\n",
      "[VGG-cam]. Epoch [4/4], Batch[2288/2862] loss: 0.261\n",
      "[VGG-cam]. Epoch [4/4], Batch[2431/2862] loss: 0.251\n",
      "[VGG-cam]. Epoch [4/4], Batch[2574/2862] loss: 0.240\n",
      "[VGG-cam]. Epoch [4/4], Batch[2717/2862] loss: 0.234\n",
      "[VGG-cam]. Epoch [4/4], Batch[2860/2862] loss: 0.227\n",
      "[VGG-cam]. Epoch [4/4], Batch[2861/2862] loss: 0.227\n",
      "val Loss: 0.2270 Acc: 0.9497\n",
      "\n",
      "Training complete in 9m 17s\n",
      "Best val Acc: 0.9794 Best val loss: 0.0575\n",
      "model_VGG-cam guardado\n",
      "Clases:  ['Benign', 'Pathological']\n",
      "Train image size: 11454\n",
      "Validation image size: 2862\n",
      "Test image size: 7336\n",
      "Dataset loaded.\n",
      "\n",
      "\n",
      " CAM_PRO\n",
      "model_vgg-cam_pro not found\n",
      "Epoch 1/4\n",
      "----------\n",
      "[VGG-cam_pro]. Epoch [1/4], Batch[72/1431] loss: 0.027\n",
      "[VGG-cam_pro]. Epoch [1/4], Batch[144/1431] loss: 0.022\n",
      "[VGG-cam_pro]. Epoch [1/4], Batch[216/1431] loss: 0.017\n",
      "[VGG-cam_pro]. Epoch [1/4], Batch[288/1431] loss: 0.016\n",
      "[VGG-cam_pro]. Epoch [1/4], Batch[360/1431] loss: 0.015\n",
      "[VGG-cam_pro]. Epoch [1/4], Batch[432/1431] loss: 0.016\n",
      "[VGG-cam_pro]. Epoch [1/4], Batch[504/1431] loss: 0.016\n",
      "[VGG-cam_pro]. Epoch [1/4], Batch[576/1431] loss: 0.017\n",
      "[VGG-cam_pro]. Epoch [1/4], Batch[648/1431] loss: 0.016\n",
      "[VGG-cam_pro]. Epoch [1/4], Batch[720/1431] loss: 0.016\n",
      "[VGG-cam_pro]. Epoch [1/4], Batch[792/1431] loss: 0.015\n",
      "[VGG-cam_pro]. Epoch [1/4], Batch[864/1431] loss: 0.015\n",
      "[VGG-cam_pro]. Epoch [1/4], Batch[936/1431] loss: 0.015\n",
      "[VGG-cam_pro]. Epoch [1/4], Batch[1008/1431] loss: 0.015\n",
      "[VGG-cam_pro]. Epoch [1/4], Batch[1080/1431] loss: 0.014\n",
      "[VGG-cam_pro]. Epoch [1/4], Batch[1152/1431] loss: 0.014\n",
      "[VGG-cam_pro]. Epoch [1/4], Batch[1224/1431] loss: 0.014\n",
      "[VGG-cam_pro]. Epoch [1/4], Batch[1296/1431] loss: 0.014\n",
      "[VGG-cam_pro]. Epoch [1/4], Batch[1368/1431] loss: 0.014\n",
      "train Loss: 0.0134 Acc: 0.9660\n",
      "\n",
      "[VGG-cam_pro]. Epoch [1/4], Batch[143/2862] loss: 0.000\n",
      "[VGG-cam_pro]. Epoch [1/4], Batch[286/2862] loss: 0.002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VGG-cam_pro]. Epoch [1/4], Batch[429/2862] loss: 0.003\n",
      "[VGG-cam_pro]. Epoch [1/4], Batch[572/2862] loss: 0.002\n",
      "[VGG-cam_pro]. Epoch [1/4], Batch[715/2862] loss: 0.002\n",
      "[VGG-cam_pro]. Epoch [1/4], Batch[858/2862] loss: 0.002\n",
      "[VGG-cam_pro]. Epoch [1/4], Batch[1001/2862] loss: 0.002\n",
      "[VGG-cam_pro]. Epoch [1/4], Batch[1144/2862] loss: 0.002\n",
      "[VGG-cam_pro]. Epoch [1/4], Batch[1287/2862] loss: 0.002\n",
      "[VGG-cam_pro]. Epoch [1/4], Batch[1430/2862] loss: 0.002\n",
      "[VGG-cam_pro]. Epoch [1/4], Batch[1573/2862] loss: 0.003\n",
      "[VGG-cam_pro]. Epoch [1/4], Batch[1716/2862] loss: 0.003\n",
      "[VGG-cam_pro]. Epoch [1/4], Batch[1859/2862] loss: 0.003\n",
      "[VGG-cam_pro]. Epoch [1/4], Batch[2002/2862] loss: 0.002\n",
      "[VGG-cam_pro]. Epoch [1/4], Batch[2145/2862] loss: 0.003\n",
      "[VGG-cam_pro]. Epoch [1/4], Batch[2288/2862] loss: 0.009\n",
      "[VGG-cam_pro]. Epoch [1/4], Batch[2431/2862] loss: 0.066\n",
      "[VGG-cam_pro]. Epoch [1/4], Batch[2574/2862] loss: 0.080\n",
      "[VGG-cam_pro]. Epoch [1/4], Batch[2717/2862] loss: 0.106\n",
      "[VGG-cam_pro]. Epoch [1/4], Batch[2860/2862] loss: 0.135\n",
      "[VGG-cam_pro]. Epoch [1/4], Batch[2861/2862] loss: 0.136\n",
      "val Loss: 0.1355 Acc: 0.9581\n",
      "New best model found!\n",
      "New record loss: 0.1355266072987067, previous record loss: inf\n",
      "técnica:  gradcam\n",
      "LONGITUD DEL HEATMAPS:  447\n",
      "Técnica:  gradcam\n",
      "técnica:  gradcampp\n",
      "LONGITUD DEL HEATMAPS:  447\n",
      "Técnica:  gradcampp\n",
      "técnica:  smoothgradcampp\n",
      "LONGITUD DEL HEATMAPS:  447\n",
      "Técnica:  smoothgradcampp\n",
      "\n",
      "Epoch 2/4\n",
      "----------\n",
      "[VGG-cam_pro]. Epoch [2/4], Batch[72/1431] loss: 0.009\n",
      "[VGG-cam_pro]. Epoch [2/4], Batch[144/1431] loss: 0.010\n",
      "[VGG-cam_pro]. Epoch [2/4], Batch[216/1431] loss: 0.009\n",
      "[VGG-cam_pro]. Epoch [2/4], Batch[288/1431] loss: 0.009\n",
      "[VGG-cam_pro]. Epoch [2/4], Batch[360/1431] loss: 0.009\n",
      "[VGG-cam_pro]. Epoch [2/4], Batch[432/1431] loss: 0.008\n",
      "[VGG-cam_pro]. Epoch [2/4], Batch[504/1431] loss: 0.008\n",
      "[VGG-cam_pro]. Epoch [2/4], Batch[576/1431] loss: 0.008\n",
      "[VGG-cam_pro]. Epoch [2/4], Batch[648/1431] loss: 0.008\n",
      "[VGG-cam_pro]. Epoch [2/4], Batch[720/1431] loss: 0.008\n",
      "[VGG-cam_pro]. Epoch [2/4], Batch[792/1431] loss: 0.008\n",
      "[VGG-cam_pro]. Epoch [2/4], Batch[864/1431] loss: 0.008\n",
      "[VGG-cam_pro]. Epoch [2/4], Batch[936/1431] loss: 0.008\n",
      "[VGG-cam_pro]. Epoch [2/4], Batch[1008/1431] loss: 0.008\n",
      "[VGG-cam_pro]. Epoch [2/4], Batch[1080/1431] loss: 0.008\n",
      "[VGG-cam_pro]. Epoch [2/4], Batch[1152/1431] loss: 0.008\n",
      "[VGG-cam_pro]. Epoch [2/4], Batch[1224/1431] loss: 0.008\n",
      "[VGG-cam_pro]. Epoch [2/4], Batch[1296/1431] loss: 0.008\n",
      "[VGG-cam_pro]. Epoch [2/4], Batch[1368/1431] loss: 0.008\n",
      "train Loss: 0.0078 Acc: 0.9804\n",
      "\n",
      "[VGG-cam_pro]. Epoch [2/4], Batch[143/2862] loss: 0.000\n",
      "[VGG-cam_pro]. Epoch [2/4], Batch[286/2862] loss: 0.001\n",
      "[VGG-cam_pro]. Epoch [2/4], Batch[429/2862] loss: 0.002\n",
      "[VGG-cam_pro]. Epoch [2/4], Batch[572/2862] loss: 0.002\n",
      "[VGG-cam_pro]. Epoch [2/4], Batch[715/2862] loss: 0.002\n",
      "[VGG-cam_pro]. Epoch [2/4], Batch[858/2862] loss: 0.001\n",
      "[VGG-cam_pro]. Epoch [2/4], Batch[1001/2862] loss: 0.001\n",
      "[VGG-cam_pro]. Epoch [2/4], Batch[1144/2862] loss: 0.002\n",
      "[VGG-cam_pro]. Epoch [2/4], Batch[1287/2862] loss: 0.002\n",
      "[VGG-cam_pro]. Epoch [2/4], Batch[1430/2862] loss: 0.002\n",
      "[VGG-cam_pro]. Epoch [2/4], Batch[1573/2862] loss: 0.004\n",
      "[VGG-cam_pro]. Epoch [2/4], Batch[1716/2862] loss: 0.003\n",
      "[VGG-cam_pro]. Epoch [2/4], Batch[1859/2862] loss: 0.004\n",
      "[VGG-cam_pro]. Epoch [2/4], Batch[2002/2862] loss: 0.004\n",
      "[VGG-cam_pro]. Epoch [2/4], Batch[2145/2862] loss: 0.003\n",
      "[VGG-cam_pro]. Epoch [2/4], Batch[2288/2862] loss: 0.004\n",
      "[VGG-cam_pro]. Epoch [2/4], Batch[2431/2862] loss: 0.019\n",
      "[VGG-cam_pro]. Epoch [2/4], Batch[2574/2862] loss: 0.021\n",
      "[VGG-cam_pro]. Epoch [2/4], Batch[2717/2862] loss: 0.045\n",
      "[VGG-cam_pro]. Epoch [2/4], Batch[2860/2862] loss: 0.068\n",
      "[VGG-cam_pro]. Epoch [2/4], Batch[2861/2862] loss: 0.068\n",
      "val Loss: 0.0683 Acc: 0.9790\n",
      "New best model found!\n",
      "New record loss: 0.06830091436347946, previous record loss: 0.1355266072987067\n",
      "técnica:  gradcam\n",
      "LONGITUD DEL HEATMAPS:  447\n",
      "Técnica:  gradcam\n",
      "técnica:  gradcampp\n",
      "LONGITUD DEL HEATMAPS:  447\n",
      "Técnica:  gradcampp\n",
      "técnica:  smoothgradcampp\n",
      "LONGITUD DEL HEATMAPS:  447\n",
      "Técnica:  smoothgradcampp\n",
      "\n",
      "Epoch 3/4\n",
      "----------\n",
      "[VGG-cam_pro]. Epoch [3/4], Batch[72/1431] loss: 0.008\n",
      "[VGG-cam_pro]. Epoch [3/4], Batch[144/1431] loss: 0.009\n",
      "[VGG-cam_pro]. Epoch [3/4], Batch[216/1431] loss: 0.007\n",
      "[VGG-cam_pro]. Epoch [3/4], Batch[288/1431] loss: 0.006\n",
      "[VGG-cam_pro]. Epoch [3/4], Batch[360/1431] loss: 0.007\n",
      "[VGG-cam_pro]. Epoch [3/4], Batch[432/1431] loss: 0.006\n",
      "[VGG-cam_pro]. Epoch [3/4], Batch[504/1431] loss: 0.006\n",
      "[VGG-cam_pro]. Epoch [3/4], Batch[576/1431] loss: 0.006\n",
      "[VGG-cam_pro]. Epoch [3/4], Batch[648/1431] loss: 0.005\n",
      "[VGG-cam_pro]. Epoch [3/4], Batch[720/1431] loss: 0.005\n",
      "[VGG-cam_pro]. Epoch [3/4], Batch[792/1431] loss: 0.005\n",
      "[VGG-cam_pro]. Epoch [3/4], Batch[864/1431] loss: 0.006\n",
      "[VGG-cam_pro]. Epoch [3/4], Batch[936/1431] loss: 0.006\n",
      "[VGG-cam_pro]. Epoch [3/4], Batch[1008/1431] loss: 0.006\n",
      "[VGG-cam_pro]. Epoch [3/4], Batch[1080/1431] loss: 0.006\n",
      "[VGG-cam_pro]. Epoch [3/4], Batch[1152/1431] loss: 0.006\n",
      "[VGG-cam_pro]. Epoch [3/4], Batch[1224/1431] loss: 0.006\n",
      "[VGG-cam_pro]. Epoch [3/4], Batch[1296/1431] loss: 0.005\n",
      "[VGG-cam_pro]. Epoch [3/4], Batch[1368/1431] loss: 0.005\n",
      "train Loss: 0.0055 Acc: 0.9860\n",
      "\n",
      "[VGG-cam_pro]. Epoch [3/4], Batch[143/2862] loss: 0.002\n",
      "[VGG-cam_pro]. Epoch [3/4], Batch[286/2862] loss: 0.016\n",
      "[VGG-cam_pro]. Epoch [3/4], Batch[429/2862] loss: 0.013\n",
      "[VGG-cam_pro]. Epoch [3/4], Batch[572/2862] loss: 0.010\n",
      "[VGG-cam_pro]. Epoch [3/4], Batch[715/2862] loss: 0.010\n",
      "[VGG-cam_pro]. Epoch [3/4], Batch[858/2862] loss: 0.009\n",
      "[VGG-cam_pro]. Epoch [3/4], Batch[1001/2862] loss: 0.008\n",
      "[VGG-cam_pro]. Epoch [3/4], Batch[1144/2862] loss: 0.008\n",
      "[VGG-cam_pro]. Epoch [3/4], Batch[1287/2862] loss: 0.008\n",
      "[VGG-cam_pro]. Epoch [3/4], Batch[1430/2862] loss: 0.008\n",
      "[VGG-cam_pro]. Epoch [3/4], Batch[1573/2862] loss: 0.008\n",
      "[VGG-cam_pro]. Epoch [3/4], Batch[1716/2862] loss: 0.007\n",
      "[VGG-cam_pro]. Epoch [3/4], Batch[1859/2862] loss: 0.007\n",
      "[VGG-cam_pro]. Epoch [3/4], Batch[2002/2862] loss: 0.007\n",
      "[VGG-cam_pro]. Epoch [3/4], Batch[2145/2862] loss: 0.007\n",
      "[VGG-cam_pro]. Epoch [3/4], Batch[2288/2862] loss: 0.007\n",
      "[VGG-cam_pro]. Epoch [3/4], Batch[2431/2862] loss: 0.012\n",
      "[VGG-cam_pro]. Epoch [3/4], Batch[2574/2862] loss: 0.011\n",
      "[VGG-cam_pro]. Epoch [3/4], Batch[2717/2862] loss: 0.022\n",
      "[VGG-cam_pro]. Epoch [3/4], Batch[2860/2862] loss: 0.026\n",
      "[VGG-cam_pro]. Epoch [3/4], Batch[2861/2862] loss: 0.026\n",
      "val Loss: 0.0259 Acc: 0.9927\n",
      "New best model found!\n",
      "New record loss: 0.025921756541347155, previous record loss: 0.06830091436347946\n",
      "técnica:  gradcam\n",
      "LONGITUD DEL HEATMAPS:  447\n",
      "Técnica:  gradcam\n",
      "técnica:  gradcampp\n",
      "LONGITUD DEL HEATMAPS:  447\n",
      "Técnica:  gradcampp\n",
      "técnica:  smoothgradcampp\n",
      "LONGITUD DEL HEATMAPS:  447\n",
      "Técnica:  smoothgradcampp\n",
      "\n",
      "Epoch 4/4\n",
      "----------\n",
      "[VGG-cam_pro]. Epoch [4/4], Batch[72/1431] loss: 0.002\n",
      "[VGG-cam_pro]. Epoch [4/4], Batch[144/1431] loss: 0.004\n",
      "[VGG-cam_pro]. Epoch [4/4], Batch[216/1431] loss: 0.005\n",
      "[VGG-cam_pro]. Epoch [4/4], Batch[288/1431] loss: 0.006\n",
      "[VGG-cam_pro]. Epoch [4/4], Batch[360/1431] loss: 0.005\n",
      "[VGG-cam_pro]. Epoch [4/4], Batch[432/1431] loss: 0.005\n",
      "[VGG-cam_pro]. Epoch [4/4], Batch[504/1431] loss: 0.005\n",
      "[VGG-cam_pro]. Epoch [4/4], Batch[576/1431] loss: 0.005\n",
      "[VGG-cam_pro]. Epoch [4/4], Batch[648/1431] loss: 0.004\n",
      "[VGG-cam_pro]. Epoch [4/4], Batch[720/1431] loss: 0.004\n",
      "[VGG-cam_pro]. Epoch [4/4], Batch[792/1431] loss: 0.004\n",
      "[VGG-cam_pro]. Epoch [4/4], Batch[864/1431] loss: 0.005\n",
      "[VGG-cam_pro]. Epoch [4/4], Batch[936/1431] loss: 0.005\n",
      "[VGG-cam_pro]. Epoch [4/4], Batch[1008/1431] loss: 0.005\n",
      "[VGG-cam_pro]. Epoch [4/4], Batch[1080/1431] loss: 0.005\n",
      "[VGG-cam_pro]. Epoch [4/4], Batch[1152/1431] loss: 0.005\n",
      "[VGG-cam_pro]. Epoch [4/4], Batch[1224/1431] loss: 0.005\n",
      "[VGG-cam_pro]. Epoch [4/4], Batch[1296/1431] loss: 0.005\n",
      "[VGG-cam_pro]. Epoch [4/4], Batch[1368/1431] loss: 0.005\n",
      "train Loss: 0.0049 Acc: 0.9892\n",
      "\n",
      "[VGG-cam_pro]. Epoch [4/4], Batch[143/2862] loss: 0.009\n",
      "[VGG-cam_pro]. Epoch [4/4], Batch[286/2862] loss: 0.021\n",
      "[VGG-cam_pro]. Epoch [4/4], Batch[429/2862] loss: 0.025\n",
      "[VGG-cam_pro]. Epoch [4/4], Batch[572/2862] loss: 0.019\n",
      "[VGG-cam_pro]. Epoch [4/4], Batch[715/2862] loss: 0.023\n",
      "[VGG-cam_pro]. Epoch [4/4], Batch[858/2862] loss: 0.020\n",
      "[VGG-cam_pro]. Epoch [4/4], Batch[1001/2862] loss: 0.017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VGG-cam_pro]. Epoch [4/4], Batch[1144/2862] loss: 0.019\n",
      "[VGG-cam_pro]. Epoch [4/4], Batch[1287/2862] loss: 0.019\n",
      "[VGG-cam_pro]. Epoch [4/4], Batch[1430/2862] loss: 0.018\n",
      "[VGG-cam_pro]. Epoch [4/4], Batch[1573/2862] loss: 0.019\n",
      "[VGG-cam_pro]. Epoch [4/4], Batch[1716/2862] loss: 0.018\n",
      "[VGG-cam_pro]. Epoch [4/4], Batch[1859/2862] loss: 0.017\n",
      "[VGG-cam_pro]. Epoch [4/4], Batch[2002/2862] loss: 0.016\n",
      "[VGG-cam_pro]. Epoch [4/4], Batch[2145/2862] loss: 0.016\n",
      "[VGG-cam_pro]. Epoch [4/4], Batch[2288/2862] loss: 0.015\n",
      "[VGG-cam_pro]. Epoch [4/4], Batch[2431/2862] loss: 0.018\n",
      "[VGG-cam_pro]. Epoch [4/4], Batch[2574/2862] loss: 0.017\n",
      "[VGG-cam_pro]. Epoch [4/4], Batch[2717/2862] loss: 0.021\n",
      "[VGG-cam_pro]. Epoch [4/4], Batch[2860/2862] loss: 0.023\n",
      "[VGG-cam_pro]. Epoch [4/4], Batch[2861/2862] loss: 0.023\n",
      "val Loss: 0.0235 Acc: 0.9923\n",
      "New best model found!\n",
      "New record loss: 0.023455447771501815, previous record loss: 0.025921756541347155\n",
      "técnica:  gradcam\n",
      "LONGITUD DEL HEATMAPS:  447\n",
      "Técnica:  gradcam\n",
      "técnica:  gradcampp\n",
      "LONGITUD DEL HEATMAPS:  447\n",
      "Técnica:  gradcampp\n",
      "técnica:  smoothgradcampp\n",
      "LONGITUD DEL HEATMAPS:  447\n",
      "Técnica:  smoothgradcampp\n",
      "\n",
      "Training complete in 55m 8s\n",
      "Best val Acc: 0.9923 Best val loss: 0.0235\n",
      "model_VGG-cam_pro guardado\n",
      "Clases:  ['Benign', 'Pathological']\n",
      "Train image size: 11454\n",
      "Validation image size: 2862\n",
      "Test image size: 7336\n",
      "Dataset loaded.\n",
      "\n",
      "\n",
      " CAM\n",
      "model_resnet-cam not found\n",
      "Epoch 1/4\n",
      "----------\n",
      "[RESNET-cam]. Epoch [1/4], Batch[72/1431] loss: 0.040\n",
      "[RESNET-cam]. Epoch [1/4], Batch[144/1431] loss: 0.035\n",
      "[RESNET-cam]. Epoch [1/4], Batch[216/1431] loss: 0.032\n",
      "[RESNET-cam]. Epoch [1/4], Batch[288/1431] loss: 0.032\n",
      "[RESNET-cam]. Epoch [1/4], Batch[360/1431] loss: 0.029\n",
      "[RESNET-cam]. Epoch [1/4], Batch[432/1431] loss: 0.027\n",
      "[RESNET-cam]. Epoch [1/4], Batch[504/1431] loss: 0.025\n",
      "[RESNET-cam]. Epoch [1/4], Batch[576/1431] loss: 0.025\n",
      "[RESNET-cam]. Epoch [1/4], Batch[648/1431] loss: 0.024\n",
      "[RESNET-cam]. Epoch [1/4], Batch[720/1431] loss: 0.023\n",
      "[RESNET-cam]. Epoch [1/4], Batch[792/1431] loss: 0.023\n",
      "[RESNET-cam]. Epoch [1/4], Batch[864/1431] loss: 0.022\n",
      "[RESNET-cam]. Epoch [1/4], Batch[936/1431] loss: 0.021\n",
      "[RESNET-cam]. Epoch [1/4], Batch[1008/1431] loss: 0.021\n",
      "[RESNET-cam]. Epoch [1/4], Batch[1080/1431] loss: 0.021\n",
      "[RESNET-cam]. Epoch [1/4], Batch[1152/1431] loss: 0.020\n",
      "[RESNET-cam]. Epoch [1/4], Batch[1224/1431] loss: 0.020\n",
      "[RESNET-cam]. Epoch [1/4], Batch[1296/1431] loss: 0.019\n",
      "[RESNET-cam]. Epoch [1/4], Batch[1368/1431] loss: 0.019\n",
      "train Loss: 0.0187 Acc: 0.9427\n",
      "\n",
      "[RESNET-cam]. Epoch [1/4], Batch[143/2862] loss: 0.001\n",
      "[RESNET-cam]. Epoch [1/4], Batch[286/2862] loss: 0.022\n",
      "[RESNET-cam]. Epoch [1/4], Batch[429/2862] loss: 0.039\n",
      "[RESNET-cam]. Epoch [1/4], Batch[572/2862] loss: 0.030\n",
      "[RESNET-cam]. Epoch [1/4], Batch[715/2862] loss: 0.024\n",
      "[RESNET-cam]. Epoch [1/4], Batch[858/2862] loss: 0.020\n",
      "[RESNET-cam]. Epoch [1/4], Batch[1001/2862] loss: 0.018\n",
      "[RESNET-cam]. Epoch [1/4], Batch[1144/2862] loss: 0.018\n",
      "[RESNET-cam]. Epoch [1/4], Batch[1287/2862] loss: 0.016\n",
      "[RESNET-cam]. Epoch [1/4], Batch[1430/2862] loss: 0.015\n",
      "[RESNET-cam]. Epoch [1/4], Batch[1573/2862] loss: 0.015\n",
      "[RESNET-cam]. Epoch [1/4], Batch[1716/2862] loss: 0.015\n",
      "[RESNET-cam]. Epoch [1/4], Batch[1859/2862] loss: 0.015\n",
      "[RESNET-cam]. Epoch [1/4], Batch[2002/2862] loss: 0.014\n",
      "[RESNET-cam]. Epoch [1/4], Batch[2145/2862] loss: 0.014\n",
      "[RESNET-cam]. Epoch [1/4], Batch[2288/2862] loss: 0.014\n",
      "[RESNET-cam]. Epoch [1/4], Batch[2431/2862] loss: 0.022\n",
      "[RESNET-cam]. Epoch [1/4], Batch[2574/2862] loss: 0.023\n",
      "[RESNET-cam]. Epoch [1/4], Batch[2717/2862] loss: 0.027\n",
      "[RESNET-cam]. Epoch [1/4], Batch[2860/2862] loss: 0.035\n",
      "[RESNET-cam]. Epoch [1/4], Batch[2861/2862] loss: 0.035\n",
      "val Loss: 0.0352 Acc: 0.9881\n",
      "New best model found!\n",
      "New record loss: 0.03517231612056988, previous record loss: inf\n",
      "técnica:  cam\n",
      "LONGITUD DEL HEATMAPS:  447\n",
      "Técnica:  cam\n",
      "\n",
      "Epoch 2/4\n",
      "----------\n",
      "[RESNET-cam]. Epoch [2/4], Batch[72/1431] loss: 0.009\n",
      "[RESNET-cam]. Epoch [2/4], Batch[144/1431] loss: 0.014\n",
      "[RESNET-cam]. Epoch [2/4], Batch[216/1431] loss: 0.012\n",
      "[RESNET-cam]. Epoch [2/4], Batch[288/1431] loss: 0.010\n",
      "[RESNET-cam]. Epoch [2/4], Batch[360/1431] loss: 0.010\n",
      "[RESNET-cam]. Epoch [2/4], Batch[432/1431] loss: 0.010\n",
      "[RESNET-cam]. Epoch [2/4], Batch[504/1431] loss: 0.010\n",
      "[RESNET-cam]. Epoch [2/4], Batch[576/1431] loss: 0.010\n",
      "[RESNET-cam]. Epoch [2/4], Batch[648/1431] loss: 0.010\n",
      "[RESNET-cam]. Epoch [2/4], Batch[720/1431] loss: 0.010\n",
      "[RESNET-cam]. Epoch [2/4], Batch[792/1431] loss: 0.009\n",
      "[RESNET-cam]. Epoch [2/4], Batch[864/1431] loss: 0.009\n",
      "[RESNET-cam]. Epoch [2/4], Batch[936/1431] loss: 0.009\n",
      "[RESNET-cam]. Epoch [2/4], Batch[1008/1431] loss: 0.009\n",
      "[RESNET-cam]. Epoch [2/4], Batch[1080/1431] loss: 0.009\n",
      "[RESNET-cam]. Epoch [2/4], Batch[1152/1431] loss: 0.009\n",
      "[RESNET-cam]. Epoch [2/4], Batch[1224/1431] loss: 0.009\n",
      "[RESNET-cam]. Epoch [2/4], Batch[1296/1431] loss: 0.009\n",
      "[RESNET-cam]. Epoch [2/4], Batch[1368/1431] loss: 0.009\n",
      "train Loss: 0.0086 Acc: 0.9764\n",
      "\n",
      "[RESNET-cam]. Epoch [2/4], Batch[143/2862] loss: 0.160\n",
      "[RESNET-cam]. Epoch [2/4], Batch[286/2862] loss: 0.172\n",
      "[RESNET-cam]. Epoch [2/4], Batch[429/2862] loss: 0.217\n",
      "[RESNET-cam]. Epoch [2/4], Batch[572/2862] loss: 0.189\n",
      "[RESNET-cam]. Epoch [2/4], Batch[715/2862] loss: 0.169\n",
      "[RESNET-cam]. Epoch [2/4], Batch[858/2862] loss: 0.146\n",
      "[RESNET-cam]. Epoch [2/4], Batch[1001/2862] loss: 0.127\n",
      "[RESNET-cam]. Epoch [2/4], Batch[1144/2862] loss: 0.113\n",
      "[RESNET-cam]. Epoch [2/4], Batch[1287/2862] loss: 0.105\n",
      "[RESNET-cam]. Epoch [2/4], Batch[1430/2862] loss: 0.096\n",
      "[RESNET-cam]. Epoch [2/4], Batch[1573/2862] loss: 0.114\n",
      "[RESNET-cam]. Epoch [2/4], Batch[1716/2862] loss: 0.124\n",
      "[RESNET-cam]. Epoch [2/4], Batch[1859/2862] loss: 0.155\n",
      "[RESNET-cam]. Epoch [2/4], Batch[2002/2862] loss: 0.168\n",
      "[RESNET-cam]. Epoch [2/4], Batch[2145/2862] loss: 0.184\n",
      "[RESNET-cam]. Epoch [2/4], Batch[2288/2862] loss: 0.179\n",
      "[RESNET-cam]. Epoch [2/4], Batch[2431/2862] loss: 0.169\n",
      "[RESNET-cam]. Epoch [2/4], Batch[2574/2862] loss: 0.160\n",
      "[RESNET-cam]. Epoch [2/4], Batch[2717/2862] loss: 0.153\n",
      "[RESNET-cam]. Epoch [2/4], Batch[2860/2862] loss: 0.146\n",
      "[RESNET-cam]. Epoch [2/4], Batch[2861/2862] loss: 0.146\n",
      "val Loss: 0.1458 Acc: 0.9354\n",
      "\n",
      "Epoch 3/4\n",
      "----------\n",
      "[RESNET-cam]. Epoch [3/4], Batch[72/1431] loss: 0.010\n",
      "[RESNET-cam]. Epoch [3/4], Batch[144/1431] loss: 0.008\n",
      "[RESNET-cam]. Epoch [3/4], Batch[216/1431] loss: 0.007\n",
      "[RESNET-cam]. Epoch [3/4], Batch[288/1431] loss: 0.007\n",
      "[RESNET-cam]. Epoch [3/4], Batch[360/1431] loss: 0.006\n",
      "[RESNET-cam]. Epoch [3/4], Batch[432/1431] loss: 0.006\n",
      "[RESNET-cam]. Epoch [3/4], Batch[504/1431] loss: 0.007\n",
      "[RESNET-cam]. Epoch [3/4], Batch[576/1431] loss: 0.007\n",
      "[RESNET-cam]. Epoch [3/4], Batch[648/1431] loss: 0.007\n",
      "[RESNET-cam]. Epoch [3/4], Batch[720/1431] loss: 0.007\n",
      "[RESNET-cam]. Epoch [3/4], Batch[792/1431] loss: 0.006\n",
      "[RESNET-cam]. Epoch [3/4], Batch[864/1431] loss: 0.006\n",
      "[RESNET-cam]. Epoch [3/4], Batch[936/1431] loss: 0.006\n",
      "[RESNET-cam]. Epoch [3/4], Batch[1008/1431] loss: 0.006\n",
      "[RESNET-cam]. Epoch [3/4], Batch[1080/1431] loss: 0.006\n",
      "[RESNET-cam]. Epoch [3/4], Batch[1152/1431] loss: 0.006\n",
      "[RESNET-cam]. Epoch [3/4], Batch[1224/1431] loss: 0.006\n",
      "[RESNET-cam]. Epoch [3/4], Batch[1296/1431] loss: 0.006\n",
      "[RESNET-cam]. Epoch [3/4], Batch[1368/1431] loss: 0.006\n",
      "train Loss: 0.0058 Acc: 0.9829\n",
      "\n",
      "[RESNET-cam]. Epoch [3/4], Batch[143/2862] loss: 0.003\n",
      "[RESNET-cam]. Epoch [3/4], Batch[286/2862] loss: 0.005\n",
      "[RESNET-cam]. Epoch [3/4], Batch[429/2862] loss: 0.007\n",
      "[RESNET-cam]. Epoch [3/4], Batch[572/2862] loss: 0.005\n",
      "[RESNET-cam]. Epoch [3/4], Batch[715/2862] loss: 0.004\n",
      "[RESNET-cam]. Epoch [3/4], Batch[858/2862] loss: 0.004\n",
      "[RESNET-cam]. Epoch [3/4], Batch[1001/2862] loss: 0.003\n",
      "[RESNET-cam]. Epoch [3/4], Batch[1144/2862] loss: 0.003\n",
      "[RESNET-cam]. Epoch [3/4], Batch[1287/2862] loss: 0.003\n",
      "[RESNET-cam]. Epoch [3/4], Batch[1430/2862] loss: 0.003\n",
      "[RESNET-cam]. Epoch [3/4], Batch[1573/2862] loss: 0.002\n",
      "[RESNET-cam]. Epoch [3/4], Batch[1716/2862] loss: 0.002\n",
      "[RESNET-cam]. Epoch [3/4], Batch[1859/2862] loss: 0.002\n",
      "[RESNET-cam]. Epoch [3/4], Batch[2002/2862] loss: 0.002\n",
      "[RESNET-cam]. Epoch [3/4], Batch[2145/2862] loss: 0.002\n",
      "[RESNET-cam]. Epoch [3/4], Batch[2288/2862] loss: 0.002\n",
      "[RESNET-cam]. Epoch [3/4], Batch[2431/2862] loss: 0.004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[RESNET-cam]. Epoch [3/4], Batch[2574/2862] loss: 0.006\n",
      "[RESNET-cam]. Epoch [3/4], Batch[2717/2862] loss: 0.016\n",
      "[RESNET-cam]. Epoch [3/4], Batch[2860/2862] loss: 0.017\n",
      "[RESNET-cam]. Epoch [3/4], Batch[2861/2862] loss: 0.017\n",
      "val Loss: 0.0174 Acc: 0.9958\n",
      "New best model found!\n",
      "New record loss: 0.017429104277091555, previous record loss: 0.03517231612056988\n",
      "técnica:  cam\n",
      "LONGITUD DEL HEATMAPS:  447\n",
      "Técnica:  cam\n",
      "\n",
      "Epoch 4/4\n",
      "----------\n",
      "[RESNET-cam]. Epoch [4/4], Batch[72/1431] loss: 0.003\n",
      "[RESNET-cam]. Epoch [4/4], Batch[144/1431] loss: 0.003\n",
      "[RESNET-cam]. Epoch [4/4], Batch[216/1431] loss: 0.003\n",
      "[RESNET-cam]. Epoch [4/4], Batch[288/1431] loss: 0.003\n",
      "[RESNET-cam]. Epoch [4/4], Batch[360/1431] loss: 0.004\n",
      "[RESNET-cam]. Epoch [4/4], Batch[432/1431] loss: 0.004\n",
      "[RESNET-cam]. Epoch [4/4], Batch[504/1431] loss: 0.003\n",
      "[RESNET-cam]. Epoch [4/4], Batch[576/1431] loss: 0.003\n",
      "[RESNET-cam]. Epoch [4/4], Batch[648/1431] loss: 0.004\n",
      "[RESNET-cam]. Epoch [4/4], Batch[720/1431] loss: 0.004\n",
      "[RESNET-cam]. Epoch [4/4], Batch[792/1431] loss: 0.004\n",
      "[RESNET-cam]. Epoch [4/4], Batch[864/1431] loss: 0.004\n",
      "[RESNET-cam]. Epoch [4/4], Batch[936/1431] loss: 0.004\n",
      "[RESNET-cam]. Epoch [4/4], Batch[1008/1431] loss: 0.004\n",
      "[RESNET-cam]. Epoch [4/4], Batch[1080/1431] loss: 0.004\n",
      "[RESNET-cam]. Epoch [4/4], Batch[1152/1431] loss: 0.004\n",
      "[RESNET-cam]. Epoch [4/4], Batch[1224/1431] loss: 0.004\n",
      "[RESNET-cam]. Epoch [4/4], Batch[1296/1431] loss: 0.004\n",
      "[RESNET-cam]. Epoch [4/4], Batch[1368/1431] loss: 0.004\n",
      "train Loss: 0.0042 Acc: 0.9888\n",
      "\n",
      "[RESNET-cam]. Epoch [4/4], Batch[143/2862] loss: 0.022\n",
      "[RESNET-cam]. Epoch [4/4], Batch[286/2862] loss: 0.021\n",
      "[RESNET-cam]. Epoch [4/4], Batch[429/2862] loss: 0.052\n",
      "[RESNET-cam]. Epoch [4/4], Batch[572/2862] loss: 0.067\n",
      "[RESNET-cam]. Epoch [4/4], Batch[715/2862] loss: 0.061\n",
      "[RESNET-cam]. Epoch [4/4], Batch[858/2862] loss: 0.058\n",
      "[RESNET-cam]. Epoch [4/4], Batch[1001/2862] loss: 0.051\n",
      "[RESNET-cam]. Epoch [4/4], Batch[1144/2862] loss: 0.046\n",
      "[RESNET-cam]. Epoch [4/4], Batch[1287/2862] loss: 0.041\n",
      "[RESNET-cam]. Epoch [4/4], Batch[1430/2862] loss: 0.038\n",
      "[RESNET-cam]. Epoch [4/4], Batch[1573/2862] loss: 0.039\n",
      "[RESNET-cam]. Epoch [4/4], Batch[1716/2862] loss: 0.038\n",
      "[RESNET-cam]. Epoch [4/4], Batch[1859/2862] loss: 0.038\n",
      "[RESNET-cam]. Epoch [4/4], Batch[2002/2862] loss: 0.038\n",
      "[RESNET-cam]. Epoch [4/4], Batch[2145/2862] loss: 0.036\n",
      "[RESNET-cam]. Epoch [4/4], Batch[2288/2862] loss: 0.034\n",
      "[RESNET-cam]. Epoch [4/4], Batch[2431/2862] loss: 0.033\n",
      "[RESNET-cam]. Epoch [4/4], Batch[2574/2862] loss: 0.031\n",
      "[RESNET-cam]. Epoch [4/4], Batch[2717/2862] loss: 0.033\n",
      "[RESNET-cam]. Epoch [4/4], Batch[2860/2862] loss: 0.031\n",
      "[RESNET-cam]. Epoch [4/4], Batch[2861/2862] loss: 0.031\n",
      "val Loss: 0.0310 Acc: 0.9874\n",
      "\n",
      "Training complete in 3m 55s\n",
      "Best val Acc: 0.9958 Best val loss: 0.0174\n",
      "model_RESNET-cam guardado\n",
      "Clases:  ['Benign', 'Pathological']\n",
      "Train image size: 11454\n",
      "Validation image size: 2862\n",
      "Test image size: 7336\n",
      "Dataset loaded.\n",
      "\n",
      "\n",
      " CAM_PRO\n",
      "model_resnet-cam_pro not found\n",
      "Epoch 1/4\n",
      "----------\n",
      "[RESNET-cam_pro]. Epoch [1/4], Batch[72/1431] loss: 0.075\n",
      "[RESNET-cam_pro]. Epoch [1/4], Batch[144/1431] loss: 0.056\n",
      "[RESNET-cam_pro]. Epoch [1/4], Batch[216/1431] loss: 0.044\n",
      "[RESNET-cam_pro]. Epoch [1/4], Batch[288/1431] loss: 0.037\n",
      "[RESNET-cam_pro]. Epoch [1/4], Batch[360/1431] loss: 0.033\n",
      "[RESNET-cam_pro]. Epoch [1/4], Batch[432/1431] loss: 0.030\n",
      "[RESNET-cam_pro]. Epoch [1/4], Batch[504/1431] loss: 0.027\n",
      "[RESNET-cam_pro]. Epoch [1/4], Batch[576/1431] loss: 0.025\n",
      "[RESNET-cam_pro]. Epoch [1/4], Batch[648/1431] loss: 0.023\n",
      "[RESNET-cam_pro]. Epoch [1/4], Batch[720/1431] loss: 0.022\n",
      "[RESNET-cam_pro]. Epoch [1/4], Batch[792/1431] loss: 0.021\n",
      "[RESNET-cam_pro]. Epoch [1/4], Batch[864/1431] loss: 0.020\n",
      "[RESNET-cam_pro]. Epoch [1/4], Batch[936/1431] loss: 0.020\n",
      "[RESNET-cam_pro]. Epoch [1/4], Batch[1008/1431] loss: 0.019\n",
      "[RESNET-cam_pro]. Epoch [1/4], Batch[1080/1431] loss: 0.018\n",
      "[RESNET-cam_pro]. Epoch [1/4], Batch[1152/1431] loss: 0.018\n",
      "[RESNET-cam_pro]. Epoch [1/4], Batch[1224/1431] loss: 0.017\n",
      "[RESNET-cam_pro]. Epoch [1/4], Batch[1296/1431] loss: 0.017\n",
      "[RESNET-cam_pro]. Epoch [1/4], Batch[1368/1431] loss: 0.017\n",
      "train Loss: 0.0163 Acc: 0.9510\n",
      "\n",
      "[RESNET-cam_pro]. Epoch [1/4], Batch[143/2862] loss: 0.001\n",
      "[RESNET-cam_pro]. Epoch [1/4], Batch[286/2862] loss: 0.016\n",
      "[RESNET-cam_pro]. Epoch [1/4], Batch[429/2862] loss: 0.012\n",
      "[RESNET-cam_pro]. Epoch [1/4], Batch[572/2862] loss: 0.009\n",
      "[RESNET-cam_pro]. Epoch [1/4], Batch[715/2862] loss: 0.009\n",
      "[RESNET-cam_pro]. Epoch [1/4], Batch[858/2862] loss: 0.007\n",
      "[RESNET-cam_pro]. Epoch [1/4], Batch[1001/2862] loss: 0.006\n",
      "[RESNET-cam_pro]. Epoch [1/4], Batch[1144/2862] loss: 0.006\n",
      "[RESNET-cam_pro]. Epoch [1/4], Batch[1287/2862] loss: 0.005\n",
      "[RESNET-cam_pro]. Epoch [1/4], Batch[1430/2862] loss: 0.005\n",
      "[RESNET-cam_pro]. Epoch [1/4], Batch[1573/2862] loss: 0.006\n",
      "[RESNET-cam_pro]. Epoch [1/4], Batch[1716/2862] loss: 0.005\n",
      "[RESNET-cam_pro]. Epoch [1/4], Batch[1859/2862] loss: 0.005\n",
      "[RESNET-cam_pro]. Epoch [1/4], Batch[2002/2862] loss: 0.005\n",
      "[RESNET-cam_pro]. Epoch [1/4], Batch[2145/2862] loss: 0.005\n",
      "[RESNET-cam_pro]. Epoch [1/4], Batch[2288/2862] loss: 0.004\n",
      "[RESNET-cam_pro]. Epoch [1/4], Batch[2431/2862] loss: 0.006\n",
      "[RESNET-cam_pro]. Epoch [1/4], Batch[2574/2862] loss: 0.013\n",
      "[RESNET-cam_pro]. Epoch [1/4], Batch[2717/2862] loss: 0.021\n",
      "[RESNET-cam_pro]. Epoch [1/4], Batch[2860/2862] loss: 0.026\n",
      "[RESNET-cam_pro]. Epoch [1/4], Batch[2861/2862] loss: 0.026\n",
      "val Loss: 0.0262 Acc: 0.9923\n",
      "New best model found!\n",
      "New record loss: 0.026207144452585394, previous record loss: inf\n",
      "técnica:  gradcam\n",
      "LONGITUD DEL HEATMAPS:  447\n",
      "Técnica:  gradcam\n",
      "técnica:  gradcampp\n",
      "LONGITUD DEL HEATMAPS:  447\n",
      "Técnica:  gradcampp\n",
      "técnica:  smoothgradcampp\n",
      "LONGITUD DEL HEATMAPS:  447\n",
      "Técnica:  smoothgradcampp\n",
      "\n",
      "Epoch 2/4\n",
      "----------\n",
      "[RESNET-cam_pro]. Epoch [2/4], Batch[72/1431] loss: 0.008\n",
      "[RESNET-cam_pro]. Epoch [2/4], Batch[144/1431] loss: 0.008\n",
      "[RESNET-cam_pro]. Epoch [2/4], Batch[216/1431] loss: 0.008\n",
      "[RESNET-cam_pro]. Epoch [2/4], Batch[288/1431] loss: 0.010\n",
      "[RESNET-cam_pro]. Epoch [2/4], Batch[360/1431] loss: 0.009\n",
      "[RESNET-cam_pro]. Epoch [2/4], Batch[432/1431] loss: 0.009\n",
      "[RESNET-cam_pro]. Epoch [2/4], Batch[504/1431] loss: 0.009\n",
      "[RESNET-cam_pro]. Epoch [2/4], Batch[576/1431] loss: 0.008\n",
      "[RESNET-cam_pro]. Epoch [2/4], Batch[648/1431] loss: 0.008\n",
      "[RESNET-cam_pro]. Epoch [2/4], Batch[720/1431] loss: 0.008\n",
      "[RESNET-cam_pro]. Epoch [2/4], Batch[792/1431] loss: 0.008\n",
      "[RESNET-cam_pro]. Epoch [2/4], Batch[864/1431] loss: 0.009\n",
      "[RESNET-cam_pro]. Epoch [2/4], Batch[936/1431] loss: 0.009\n",
      "[RESNET-cam_pro]. Epoch [2/4], Batch[1008/1431] loss: 0.009\n",
      "[RESNET-cam_pro]. Epoch [2/4], Batch[1080/1431] loss: 0.009\n",
      "[RESNET-cam_pro]. Epoch [2/4], Batch[1152/1431] loss: 0.010\n",
      "[RESNET-cam_pro]. Epoch [2/4], Batch[1224/1431] loss: 0.010\n",
      "[RESNET-cam_pro]. Epoch [2/4], Batch[1296/1431] loss: 0.010\n",
      "[RESNET-cam_pro]. Epoch [2/4], Batch[1368/1431] loss: 0.010\n",
      "train Loss: 0.0096 Acc: 0.9778\n",
      "\n",
      "[RESNET-cam_pro]. Epoch [2/4], Batch[143/2862] loss: 0.005\n",
      "[RESNET-cam_pro]. Epoch [2/4], Batch[286/2862] loss: 0.007\n",
      "[RESNET-cam_pro]. Epoch [2/4], Batch[429/2862] loss: 0.006\n",
      "[RESNET-cam_pro]. Epoch [2/4], Batch[572/2862] loss: 0.004\n",
      "[RESNET-cam_pro]. Epoch [2/4], Batch[715/2862] loss: 0.004\n",
      "[RESNET-cam_pro]. Epoch [2/4], Batch[858/2862] loss: 0.005\n",
      "[RESNET-cam_pro]. Epoch [2/4], Batch[1001/2862] loss: 0.005\n",
      "[RESNET-cam_pro]. Epoch [2/4], Batch[1144/2862] loss: 0.005\n",
      "[RESNET-cam_pro]. Epoch [2/4], Batch[1287/2862] loss: 0.004\n",
      "[RESNET-cam_pro]. Epoch [2/4], Batch[1430/2862] loss: 0.004\n",
      "[RESNET-cam_pro]. Epoch [2/4], Batch[1573/2862] loss: 0.004\n",
      "[RESNET-cam_pro]. Epoch [2/4], Batch[1716/2862] loss: 0.004\n",
      "[RESNET-cam_pro]. Epoch [2/4], Batch[1859/2862] loss: 0.003\n",
      "[RESNET-cam_pro]. Epoch [2/4], Batch[2002/2862] loss: 0.003\n",
      "[RESNET-cam_pro]. Epoch [2/4], Batch[2145/2862] loss: 0.003\n",
      "[RESNET-cam_pro]. Epoch [2/4], Batch[2288/2862] loss: 0.004\n",
      "[RESNET-cam_pro]. Epoch [2/4], Batch[2431/2862] loss: 0.007\n",
      "[RESNET-cam_pro]. Epoch [2/4], Batch[2574/2862] loss: 0.012\n",
      "[RESNET-cam_pro]. Epoch [2/4], Batch[2717/2862] loss: 0.022\n",
      "[RESNET-cam_pro]. Epoch [2/4], Batch[2860/2862] loss: 0.025\n",
      "[RESNET-cam_pro]. Epoch [2/4], Batch[2861/2862] loss: 0.025\n",
      "val Loss: 0.0250 Acc: 0.9902\n",
      "New best model found!\n",
      "New record loss: 0.024993343351064484, previous record loss: 0.026207144452585394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "técnica:  gradcam\n",
      "LONGITUD DEL HEATMAPS:  447\n",
      "Técnica:  gradcam\n",
      "técnica:  gradcampp\n",
      "LONGITUD DEL HEATMAPS:  447\n",
      "Técnica:  gradcampp\n",
      "técnica:  smoothgradcampp\n",
      "LONGITUD DEL HEATMAPS:  447\n",
      "Técnica:  smoothgradcampp\n",
      "\n",
      "Epoch 3/4\n",
      "----------\n",
      "[RESNET-cam_pro]. Epoch [3/4], Batch[72/1431] loss: 0.006\n",
      "[RESNET-cam_pro]. Epoch [3/4], Batch[144/1431] loss: 0.006\n",
      "[RESNET-cam_pro]. Epoch [3/4], Batch[216/1431] loss: 0.005\n",
      "[RESNET-cam_pro]. Epoch [3/4], Batch[288/1431] loss: 0.005\n",
      "[RESNET-cam_pro]. Epoch [3/4], Batch[360/1431] loss: 0.005\n",
      "[RESNET-cam_pro]. Epoch [3/4], Batch[432/1431] loss: 0.006\n",
      "[RESNET-cam_pro]. Epoch [3/4], Batch[504/1431] loss: 0.005\n",
      "[RESNET-cam_pro]. Epoch [3/4], Batch[576/1431] loss: 0.006\n",
      "[RESNET-cam_pro]. Epoch [3/4], Batch[648/1431] loss: 0.006\n",
      "[RESNET-cam_pro]. Epoch [3/4], Batch[720/1431] loss: 0.006\n",
      "[RESNET-cam_pro]. Epoch [3/4], Batch[792/1431] loss: 0.006\n",
      "[RESNET-cam_pro]. Epoch [3/4], Batch[864/1431] loss: 0.006\n",
      "[RESNET-cam_pro]. Epoch [3/4], Batch[936/1431] loss: 0.006\n",
      "[RESNET-cam_pro]. Epoch [3/4], Batch[1008/1431] loss: 0.006\n",
      "[RESNET-cam_pro]. Epoch [3/4], Batch[1080/1431] loss: 0.007\n",
      "[RESNET-cam_pro]. Epoch [3/4], Batch[1152/1431] loss: 0.007\n",
      "[RESNET-cam_pro]. Epoch [3/4], Batch[1224/1431] loss: 0.007\n",
      "[RESNET-cam_pro]. Epoch [3/4], Batch[1296/1431] loss: 0.007\n",
      "[RESNET-cam_pro]. Epoch [3/4], Batch[1368/1431] loss: 0.007\n",
      "train Loss: 0.0074 Acc: 0.9845\n",
      "\n",
      "[RESNET-cam_pro]. Epoch [3/4], Batch[143/2862] loss: 0.098\n",
      "[RESNET-cam_pro]. Epoch [3/4], Batch[286/2862] loss: 0.111\n",
      "[RESNET-cam_pro]. Epoch [3/4], Batch[429/2862] loss: 0.080\n",
      "[RESNET-cam_pro]. Epoch [3/4], Batch[572/2862] loss: 0.064\n",
      "[RESNET-cam_pro]. Epoch [3/4], Batch[715/2862] loss: 0.067\n",
      "[RESNET-cam_pro]. Epoch [3/4], Batch[858/2862] loss: 0.058\n",
      "[RESNET-cam_pro]. Epoch [3/4], Batch[1001/2862] loss: 0.051\n",
      "[RESNET-cam_pro]. Epoch [3/4], Batch[1144/2862] loss: 0.047\n",
      "[RESNET-cam_pro]. Epoch [3/4], Batch[1287/2862] loss: 0.049\n",
      "[RESNET-cam_pro]. Epoch [3/4], Batch[1430/2862] loss: 0.045\n",
      "[RESNET-cam_pro]. Epoch [3/4], Batch[1573/2862] loss: 0.046\n",
      "[RESNET-cam_pro]. Epoch [3/4], Batch[1716/2862] loss: 0.044\n",
      "[RESNET-cam_pro]. Epoch [3/4], Batch[1859/2862] loss: 0.041\n",
      "[RESNET-cam_pro]. Epoch [3/4], Batch[2002/2862] loss: 0.039\n",
      "[RESNET-cam_pro]. Epoch [3/4], Batch[2145/2862] loss: 0.038\n",
      "[RESNET-cam_pro]. Epoch [3/4], Batch[2288/2862] loss: 0.036\n",
      "[RESNET-cam_pro]. Epoch [3/4], Batch[2431/2862] loss: 0.034\n",
      "[RESNET-cam_pro]. Epoch [3/4], Batch[2574/2862] loss: 0.033\n",
      "[RESNET-cam_pro]. Epoch [3/4], Batch[2717/2862] loss: 0.033\n",
      "[RESNET-cam_pro]. Epoch [3/4], Batch[2860/2862] loss: 0.031\n",
      "[RESNET-cam_pro]. Epoch [3/4], Batch[2861/2862] loss: 0.031\n",
      "val Loss: 0.0315 Acc: 0.9909\n",
      "\n",
      "Epoch 4/4\n",
      "----------\n",
      "[RESNET-cam_pro]. Epoch [4/4], Batch[72/1431] loss: 0.008\n",
      "[RESNET-cam_pro]. Epoch [4/4], Batch[144/1431] loss: 0.008\n",
      "[RESNET-cam_pro]. Epoch [4/4], Batch[216/1431] loss: 0.007\n",
      "[RESNET-cam_pro]. Epoch [4/4], Batch[288/1431] loss: 0.007\n",
      "[RESNET-cam_pro]. Epoch [4/4], Batch[360/1431] loss: 0.007\n",
      "[RESNET-cam_pro]. Epoch [4/4], Batch[432/1431] loss: 0.007\n",
      "[RESNET-cam_pro]. Epoch [4/4], Batch[504/1431] loss: 0.007\n",
      "[RESNET-cam_pro]. Epoch [4/4], Batch[576/1431] loss: 0.007\n",
      "[RESNET-cam_pro]. Epoch [4/4], Batch[648/1431] loss: 0.007\n",
      "[RESNET-cam_pro]. Epoch [4/4], Batch[720/1431] loss: 0.008\n",
      "[RESNET-cam_pro]. Epoch [4/4], Batch[792/1431] loss: 0.007\n",
      "[RESNET-cam_pro]. Epoch [4/4], Batch[864/1431] loss: 0.007\n",
      "[RESNET-cam_pro]. Epoch [4/4], Batch[936/1431] loss: 0.007\n",
      "[RESNET-cam_pro]. Epoch [4/4], Batch[1008/1431] loss: 0.007\n",
      "[RESNET-cam_pro]. Epoch [4/4], Batch[1080/1431] loss: 0.006\n",
      "[RESNET-cam_pro]. Epoch [4/4], Batch[1152/1431] loss: 0.006\n",
      "[RESNET-cam_pro]. Epoch [4/4], Batch[1224/1431] loss: 0.006\n",
      "[RESNET-cam_pro]. Epoch [4/4], Batch[1296/1431] loss: 0.006\n",
      "[RESNET-cam_pro]. Epoch [4/4], Batch[1368/1431] loss: 0.006\n",
      "train Loss: 0.0062 Acc: 0.9870\n",
      "\n",
      "[RESNET-cam_pro]. Epoch [4/4], Batch[143/2862] loss: 0.000\n",
      "[RESNET-cam_pro]. Epoch [4/4], Batch[286/2862] loss: 0.001\n",
      "[RESNET-cam_pro]. Epoch [4/4], Batch[429/2862] loss: 0.003\n",
      "[RESNET-cam_pro]. Epoch [4/4], Batch[572/2862] loss: 0.002\n",
      "[RESNET-cam_pro]. Epoch [4/4], Batch[715/2862] loss: 0.002\n",
      "[RESNET-cam_pro]. Epoch [4/4], Batch[858/2862] loss: 0.002\n",
      "[RESNET-cam_pro]. Epoch [4/4], Batch[1001/2862] loss: 0.002\n",
      "[RESNET-cam_pro]. Epoch [4/4], Batch[1144/2862] loss: 0.002\n",
      "[RESNET-cam_pro]. Epoch [4/4], Batch[1287/2862] loss: 0.002\n",
      "[RESNET-cam_pro]. Epoch [4/4], Batch[1430/2862] loss: 0.002\n",
      "[RESNET-cam_pro]. Epoch [4/4], Batch[1573/2862] loss: 0.002\n",
      "[RESNET-cam_pro]. Epoch [4/4], Batch[1716/2862] loss: 0.002\n",
      "[RESNET-cam_pro]. Epoch [4/4], Batch[1859/2862] loss: 0.002\n",
      "[RESNET-cam_pro]. Epoch [4/4], Batch[2002/2862] loss: 0.002\n",
      "[RESNET-cam_pro]. Epoch [4/4], Batch[2145/2862] loss: 0.002\n",
      "[RESNET-cam_pro]. Epoch [4/4], Batch[2288/2862] loss: 0.003\n",
      "[RESNET-cam_pro]. Epoch [4/4], Batch[2431/2862] loss: 0.021\n",
      "[RESNET-cam_pro]. Epoch [4/4], Batch[2574/2862] loss: 0.023\n",
      "[RESNET-cam_pro]. Epoch [4/4], Batch[2717/2862] loss: 0.033\n",
      "[RESNET-cam_pro]. Epoch [4/4], Batch[2860/2862] loss: 0.032\n",
      "[RESNET-cam_pro]. Epoch [4/4], Batch[2861/2862] loss: 0.032\n",
      "val Loss: 0.0318 Acc: 0.9902\n",
      "\n",
      "Training complete in 10m 13s\n",
      "Best val Acc: 0.9902 Best val loss: 0.0250\n",
      "model_RESNET-cam_pro guardado\n",
      "Clases:  ['Benign', 'Pathological']\n",
      "Train image size: 11454\n",
      "Validation image size: 2862\n",
      "Test image size: 7336\n",
      "Dataset loaded.\n",
      "\n",
      "\n",
      " CAM\n",
      "model_mobilenet-cam not found\n",
      "Epoch 1/4\n",
      "----------\n",
      "[MOBILENET-cam]. Epoch [1/4], Batch[72/1431] loss: 0.042\n",
      "[MOBILENET-cam]. Epoch [1/4], Batch[144/1431] loss: 0.035\n",
      "[MOBILENET-cam]. Epoch [1/4], Batch[216/1431] loss: 0.031\n",
      "[MOBILENET-cam]. Epoch [1/4], Batch[288/1431] loss: 0.028\n",
      "[MOBILENET-cam]. Epoch [1/4], Batch[360/1431] loss: 0.027\n",
      "[MOBILENET-cam]. Epoch [1/4], Batch[432/1431] loss: 0.026\n",
      "[MOBILENET-cam]. Epoch [1/4], Batch[504/1431] loss: 0.025\n",
      "[MOBILENET-cam]. Epoch [1/4], Batch[576/1431] loss: 0.023\n",
      "[MOBILENET-cam]. Epoch [1/4], Batch[648/1431] loss: 0.023\n",
      "[MOBILENET-cam]. Epoch [1/4], Batch[720/1431] loss: 0.022\n",
      "[MOBILENET-cam]. Epoch [1/4], Batch[792/1431] loss: 0.022\n",
      "[MOBILENET-cam]. Epoch [1/4], Batch[864/1431] loss: 0.021\n",
      "[MOBILENET-cam]. Epoch [1/4], Batch[936/1431] loss: 0.020\n",
      "[MOBILENET-cam]. Epoch [1/4], Batch[1008/1431] loss: 0.020\n",
      "[MOBILENET-cam]. Epoch [1/4], Batch[1080/1431] loss: 0.020\n",
      "[MOBILENET-cam]. Epoch [1/4], Batch[1152/1431] loss: 0.019\n",
      "[MOBILENET-cam]. Epoch [1/4], Batch[1224/1431] loss: 0.018\n",
      "[MOBILENET-cam]. Epoch [1/4], Batch[1296/1431] loss: 0.018\n",
      "[MOBILENET-cam]. Epoch [1/4], Batch[1368/1431] loss: 0.018\n",
      "train Loss: 0.0180 Acc: 0.9457\n",
      "\n",
      "[MOBILENET-cam]. Epoch [1/4], Batch[143/2862] loss: 0.078\n",
      "[MOBILENET-cam]. Epoch [1/4], Batch[286/2862] loss: 0.084\n",
      "[MOBILENET-cam]. Epoch [1/4], Batch[429/2862] loss: 0.080\n",
      "[MOBILENET-cam]. Epoch [1/4], Batch[572/2862] loss: 0.066\n",
      "[MOBILENET-cam]. Epoch [1/4], Batch[715/2862] loss: 0.066\n",
      "[MOBILENET-cam]. Epoch [1/4], Batch[858/2862] loss: 0.063\n",
      "[MOBILENET-cam]. Epoch [1/4], Batch[1001/2862] loss: 0.058\n",
      "[MOBILENET-cam]. Epoch [1/4], Batch[1144/2862] loss: 0.057\n",
      "[MOBILENET-cam]. Epoch [1/4], Batch[1287/2862] loss: 0.055\n",
      "[MOBILENET-cam]. Epoch [1/4], Batch[1430/2862] loss: 0.051\n",
      "[MOBILENET-cam]. Epoch [1/4], Batch[1573/2862] loss: 0.056\n",
      "[MOBILENET-cam]. Epoch [1/4], Batch[1716/2862] loss: 0.053\n",
      "[MOBILENET-cam]. Epoch [1/4], Batch[1859/2862] loss: 0.049\n",
      "[MOBILENET-cam]. Epoch [1/4], Batch[2002/2862] loss: 0.047\n",
      "[MOBILENET-cam]. Epoch [1/4], Batch[2145/2862] loss: 0.047\n",
      "[MOBILENET-cam]. Epoch [1/4], Batch[2288/2862] loss: 0.046\n",
      "[MOBILENET-cam]. Epoch [1/4], Batch[2431/2862] loss: 0.049\n",
      "[MOBILENET-cam]. Epoch [1/4], Batch[2574/2862] loss: 0.050\n",
      "[MOBILENET-cam]. Epoch [1/4], Batch[2717/2862] loss: 0.054\n",
      "[MOBILENET-cam]. Epoch [1/4], Batch[2860/2862] loss: 0.058\n",
      "[MOBILENET-cam]. Epoch [1/4], Batch[2861/2862] loss: 0.058\n",
      "val Loss: 0.0581 Acc: 0.9843\n",
      "New best model found!\n",
      "New record loss: 0.05809101105809282, previous record loss: inf\n",
      "técnica:  cam\n",
      "LONGITUD DEL HEATMAPS:  447\n",
      "Técnica:  cam\n",
      "\n",
      "Epoch 2/4\n",
      "----------\n",
      "[MOBILENET-cam]. Epoch [2/4], Batch[72/1431] loss: 0.015\n",
      "[MOBILENET-cam]. Epoch [2/4], Batch[144/1431] loss: 0.013\n",
      "[MOBILENET-cam]. Epoch [2/4], Batch[216/1431] loss: 0.012\n",
      "[MOBILENET-cam]. Epoch [2/4], Batch[288/1431] loss: 0.012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MOBILENET-cam]. Epoch [2/4], Batch[360/1431] loss: 0.011\n",
      "[MOBILENET-cam]. Epoch [2/4], Batch[432/1431] loss: 0.010\n",
      "[MOBILENET-cam]. Epoch [2/4], Batch[504/1431] loss: 0.011\n",
      "[MOBILENET-cam]. Epoch [2/4], Batch[576/1431] loss: 0.011\n",
      "[MOBILENET-cam]. Epoch [2/4], Batch[648/1431] loss: 0.010\n",
      "[MOBILENET-cam]. Epoch [2/4], Batch[720/1431] loss: 0.010\n",
      "[MOBILENET-cam]. Epoch [2/4], Batch[792/1431] loss: 0.010\n",
      "[MOBILENET-cam]. Epoch [2/4], Batch[864/1431] loss: 0.010\n",
      "[MOBILENET-cam]. Epoch [2/4], Batch[936/1431] loss: 0.010\n",
      "[MOBILENET-cam]. Epoch [2/4], Batch[1008/1431] loss: 0.010\n",
      "[MOBILENET-cam]. Epoch [2/4], Batch[1080/1431] loss: 0.009\n",
      "[MOBILENET-cam]. Epoch [2/4], Batch[1152/1431] loss: 0.009\n",
      "[MOBILENET-cam]. Epoch [2/4], Batch[1224/1431] loss: 0.009\n",
      "[MOBILENET-cam]. Epoch [2/4], Batch[1296/1431] loss: 0.009\n",
      "[MOBILENET-cam]. Epoch [2/4], Batch[1368/1431] loss: 0.009\n",
      "train Loss: 0.0089 Acc: 0.9746\n",
      "\n",
      "[MOBILENET-cam]. Epoch [2/4], Batch[143/2862] loss: 0.004\n",
      "[MOBILENET-cam]. Epoch [2/4], Batch[286/2862] loss: 0.016\n",
      "[MOBILENET-cam]. Epoch [2/4], Batch[429/2862] loss: 0.014\n",
      "[MOBILENET-cam]. Epoch [2/4], Batch[572/2862] loss: 0.011\n",
      "[MOBILENET-cam]. Epoch [2/4], Batch[715/2862] loss: 0.013\n",
      "[MOBILENET-cam]. Epoch [2/4], Batch[858/2862] loss: 0.011\n",
      "[MOBILENET-cam]. Epoch [2/4], Batch[1001/2862] loss: 0.009\n",
      "[MOBILENET-cam]. Epoch [2/4], Batch[1144/2862] loss: 0.009\n",
      "[MOBILENET-cam]. Epoch [2/4], Batch[1287/2862] loss: 0.009\n",
      "[MOBILENET-cam]. Epoch [2/4], Batch[1430/2862] loss: 0.008\n",
      "[MOBILENET-cam]. Epoch [2/4], Batch[1573/2862] loss: 0.013\n",
      "[MOBILENET-cam]. Epoch [2/4], Batch[1716/2862] loss: 0.012\n",
      "[MOBILENET-cam]. Epoch [2/4], Batch[1859/2862] loss: 0.011\n",
      "[MOBILENET-cam]. Epoch [2/4], Batch[2002/2862] loss: 0.012\n",
      "[MOBILENET-cam]. Epoch [2/4], Batch[2145/2862] loss: 0.011\n",
      "[MOBILENET-cam]. Epoch [2/4], Batch[2288/2862] loss: 0.012\n",
      "[MOBILENET-cam]. Epoch [2/4], Batch[2431/2862] loss: 0.014\n",
      "[MOBILENET-cam]. Epoch [2/4], Batch[2574/2862] loss: 0.014\n",
      "[MOBILENET-cam]. Epoch [2/4], Batch[2717/2862] loss: 0.021\n",
      "[MOBILENET-cam]. Epoch [2/4], Batch[2860/2862] loss: 0.021\n",
      "[MOBILENET-cam]. Epoch [2/4], Batch[2861/2862] loss: 0.021\n",
      "val Loss: 0.0209 Acc: 0.9934\n",
      "New best model found!\n",
      "New record loss: 0.02089623659462278, previous record loss: 0.05809101105809282\n",
      "técnica:  cam\n",
      "LONGITUD DEL HEATMAPS:  447\n",
      "Técnica:  cam\n",
      "\n",
      "Epoch 3/4\n",
      "----------\n",
      "[MOBILENET-cam]. Epoch [3/4], Batch[72/1431] loss: 0.006\n",
      "[MOBILENET-cam]. Epoch [3/4], Batch[144/1431] loss: 0.005\n",
      "[MOBILENET-cam]. Epoch [3/4], Batch[216/1431] loss: 0.006\n",
      "[MOBILENET-cam]. Epoch [3/4], Batch[288/1431] loss: 0.006\n",
      "[MOBILENET-cam]. Epoch [3/4], Batch[360/1431] loss: 0.006\n",
      "[MOBILENET-cam]. Epoch [3/4], Batch[432/1431] loss: 0.006\n",
      "[MOBILENET-cam]. Epoch [3/4], Batch[504/1431] loss: 0.006\n",
      "[MOBILENET-cam]. Epoch [3/4], Batch[576/1431] loss: 0.006\n",
      "[MOBILENET-cam]. Epoch [3/4], Batch[648/1431] loss: 0.006\n",
      "[MOBILENET-cam]. Epoch [3/4], Batch[720/1431] loss: 0.006\n",
      "[MOBILENET-cam]. Epoch [3/4], Batch[792/1431] loss: 0.006\n",
      "[MOBILENET-cam]. Epoch [3/4], Batch[864/1431] loss: 0.006\n",
      "[MOBILENET-cam]. Epoch [3/4], Batch[936/1431] loss: 0.006\n",
      "[MOBILENET-cam]. Epoch [3/4], Batch[1008/1431] loss: 0.006\n",
      "[MOBILENET-cam]. Epoch [3/4], Batch[1080/1431] loss: 0.006\n",
      "[MOBILENET-cam]. Epoch [3/4], Batch[1152/1431] loss: 0.005\n",
      "[MOBILENET-cam]. Epoch [3/4], Batch[1224/1431] loss: 0.006\n",
      "[MOBILENET-cam]. Epoch [3/4], Batch[1296/1431] loss: 0.006\n",
      "[MOBILENET-cam]. Epoch [3/4], Batch[1368/1431] loss: 0.006\n",
      "train Loss: 0.0057 Acc: 0.9843\n",
      "\n",
      "[MOBILENET-cam]. Epoch [3/4], Batch[143/2862] loss: 0.003\n",
      "[MOBILENET-cam]. Epoch [3/4], Batch[286/2862] loss: 0.022\n",
      "[MOBILENET-cam]. Epoch [3/4], Batch[429/2862] loss: 0.038\n",
      "[MOBILENET-cam]. Epoch [3/4], Batch[572/2862] loss: 0.031\n",
      "[MOBILENET-cam]. Epoch [3/4], Batch[715/2862] loss: 0.035\n",
      "[MOBILENET-cam]. Epoch [3/4], Batch[858/2862] loss: 0.032\n",
      "[MOBILENET-cam]. Epoch [3/4], Batch[1001/2862] loss: 0.031\n",
      "[MOBILENET-cam]. Epoch [3/4], Batch[1144/2862] loss: 0.030\n",
      "[MOBILENET-cam]. Epoch [3/4], Batch[1287/2862] loss: 0.027\n",
      "[MOBILENET-cam]. Epoch [3/4], Batch[1430/2862] loss: 0.025\n",
      "[MOBILENET-cam]. Epoch [3/4], Batch[1573/2862] loss: 0.028\n",
      "[MOBILENET-cam]. Epoch [3/4], Batch[1716/2862] loss: 0.028\n",
      "[MOBILENET-cam]. Epoch [3/4], Batch[1859/2862] loss: 0.028\n",
      "[MOBILENET-cam]. Epoch [3/4], Batch[2002/2862] loss: 0.027\n",
      "[MOBILENET-cam]. Epoch [3/4], Batch[2145/2862] loss: 0.028\n",
      "[MOBILENET-cam]. Epoch [3/4], Batch[2288/2862] loss: 0.029\n",
      "[MOBILENET-cam]. Epoch [3/4], Batch[2431/2862] loss: 0.030\n",
      "[MOBILENET-cam]. Epoch [3/4], Batch[2574/2862] loss: 0.029\n",
      "[MOBILENET-cam]. Epoch [3/4], Batch[2717/2862] loss: 0.031\n",
      "[MOBILENET-cam]. Epoch [3/4], Batch[2860/2862] loss: 0.031\n",
      "[MOBILENET-cam]. Epoch [3/4], Batch[2861/2862] loss: 0.031\n",
      "val Loss: 0.0305 Acc: 0.9885\n",
      "\n",
      "Epoch 4/4\n",
      "----------\n",
      "[MOBILENET-cam]. Epoch [4/4], Batch[72/1431] loss: 0.008\n",
      "[MOBILENET-cam]. Epoch [4/4], Batch[144/1431] loss: 0.007\n",
      "[MOBILENET-cam]. Epoch [4/4], Batch[216/1431] loss: 0.006\n",
      "[MOBILENET-cam]. Epoch [4/4], Batch[288/1431] loss: 0.006\n",
      "[MOBILENET-cam]. Epoch [4/4], Batch[360/1431] loss: 0.006\n",
      "[MOBILENET-cam]. Epoch [4/4], Batch[432/1431] loss: 0.007\n",
      "[MOBILENET-cam]. Epoch [4/4], Batch[504/1431] loss: 0.006\n",
      "[MOBILENET-cam]. Epoch [4/4], Batch[576/1431] loss: 0.006\n",
      "[MOBILENET-cam]. Epoch [4/4], Batch[648/1431] loss: 0.006\n",
      "[MOBILENET-cam]. Epoch [4/4], Batch[720/1431] loss: 0.006\n",
      "[MOBILENET-cam]. Epoch [4/4], Batch[792/1431] loss: 0.006\n",
      "[MOBILENET-cam]. Epoch [4/4], Batch[864/1431] loss: 0.005\n",
      "[MOBILENET-cam]. Epoch [4/4], Batch[936/1431] loss: 0.006\n",
      "[MOBILENET-cam]. Epoch [4/4], Batch[1008/1431] loss: 0.005\n",
      "[MOBILENET-cam]. Epoch [4/4], Batch[1080/1431] loss: 0.005\n",
      "[MOBILENET-cam]. Epoch [4/4], Batch[1152/1431] loss: 0.005\n",
      "[MOBILENET-cam]. Epoch [4/4], Batch[1224/1431] loss: 0.005\n",
      "[MOBILENET-cam]. Epoch [4/4], Batch[1296/1431] loss: 0.005\n",
      "[MOBILENET-cam]. Epoch [4/4], Batch[1368/1431] loss: 0.005\n",
      "train Loss: 0.0048 Acc: 0.9886\n",
      "\n",
      "[MOBILENET-cam]. Epoch [4/4], Batch[143/2862] loss: 0.001\n",
      "[MOBILENET-cam]. Epoch [4/4], Batch[286/2862] loss: 0.059\n",
      "[MOBILENET-cam]. Epoch [4/4], Batch[429/2862] loss: 0.060\n",
      "[MOBILENET-cam]. Epoch [4/4], Batch[572/2862] loss: 0.046\n",
      "[MOBILENET-cam]. Epoch [4/4], Batch[715/2862] loss: 0.042\n",
      "[MOBILENET-cam]. Epoch [4/4], Batch[858/2862] loss: 0.035\n",
      "[MOBILENET-cam]. Epoch [4/4], Batch[1001/2862] loss: 0.031\n",
      "[MOBILENET-cam]. Epoch [4/4], Batch[1144/2862] loss: 0.028\n",
      "[MOBILENET-cam]. Epoch [4/4], Batch[1287/2862] loss: 0.025\n",
      "[MOBILENET-cam]. Epoch [4/4], Batch[1430/2862] loss: 0.023\n",
      "[MOBILENET-cam]. Epoch [4/4], Batch[1573/2862] loss: 0.026\n",
      "[MOBILENET-cam]. Epoch [4/4], Batch[1716/2862] loss: 0.029\n",
      "[MOBILENET-cam]. Epoch [4/4], Batch[1859/2862] loss: 0.032\n",
      "[MOBILENET-cam]. Epoch [4/4], Batch[2002/2862] loss: 0.031\n",
      "[MOBILENET-cam]. Epoch [4/4], Batch[2145/2862] loss: 0.032\n",
      "[MOBILENET-cam]. Epoch [4/4], Batch[2288/2862] loss: 0.031\n",
      "[MOBILENET-cam]. Epoch [4/4], Batch[2431/2862] loss: 0.030\n",
      "[MOBILENET-cam]. Epoch [4/4], Batch[2574/2862] loss: 0.028\n",
      "[MOBILENET-cam]. Epoch [4/4], Batch[2717/2862] loss: 0.027\n",
      "[MOBILENET-cam]. Epoch [4/4], Batch[2860/2862] loss: 0.026\n",
      "[MOBILENET-cam]. Epoch [4/4], Batch[2861/2862] loss: 0.026\n",
      "val Loss: 0.0257 Acc: 0.9902\n",
      "\n",
      "Training complete in 5m 1s\n",
      "Best val Acc: 0.9934 Best val loss: 0.0209\n",
      "model_MOBILENET-cam guardado\n",
      "Clases:  ['Benign', 'Pathological']\n",
      "Train image size: 11454\n",
      "Validation image size: 2862\n",
      "Test image size: 7336\n",
      "Dataset loaded.\n",
      "\n",
      "\n",
      " CAM_PRO\n",
      "model_mobilenet-cam_pro not found\n",
      "Epoch 1/4\n",
      "----------\n",
      "[MOBILENET-cam_pro]. Epoch [1/4], Batch[72/1431] loss: 0.058\n",
      "[MOBILENET-cam_pro]. Epoch [1/4], Batch[144/1431] loss: 0.045\n",
      "[MOBILENET-cam_pro]. Epoch [1/4], Batch[216/1431] loss: 0.039\n",
      "[MOBILENET-cam_pro]. Epoch [1/4], Batch[288/1431] loss: 0.034\n",
      "[MOBILENET-cam_pro]. Epoch [1/4], Batch[360/1431] loss: 0.030\n",
      "[MOBILENET-cam_pro]. Epoch [1/4], Batch[432/1431] loss: 0.027\n",
      "[MOBILENET-cam_pro]. Epoch [1/4], Batch[504/1431] loss: 0.024\n",
      "[MOBILENET-cam_pro]. Epoch [1/4], Batch[576/1431] loss: 0.023\n",
      "[MOBILENET-cam_pro]. Epoch [1/4], Batch[648/1431] loss: 0.023\n",
      "[MOBILENET-cam_pro]. Epoch [1/4], Batch[720/1431] loss: 0.022\n",
      "[MOBILENET-cam_pro]. Epoch [1/4], Batch[792/1431] loss: 0.021\n",
      "[MOBILENET-cam_pro]. Epoch [1/4], Batch[864/1431] loss: 0.020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MOBILENET-cam_pro]. Epoch [1/4], Batch[936/1431] loss: 0.019\n",
      "[MOBILENET-cam_pro]. Epoch [1/4], Batch[1008/1431] loss: 0.018\n",
      "[MOBILENET-cam_pro]. Epoch [1/4], Batch[1080/1431] loss: 0.018\n",
      "[MOBILENET-cam_pro]. Epoch [1/4], Batch[1152/1431] loss: 0.017\n",
      "[MOBILENET-cam_pro]. Epoch [1/4], Batch[1224/1431] loss: 0.017\n",
      "[MOBILENET-cam_pro]. Epoch [1/4], Batch[1296/1431] loss: 0.017\n",
      "[MOBILENET-cam_pro]. Epoch [1/4], Batch[1368/1431] loss: 0.017\n",
      "train Loss: 0.0166 Acc: 0.9525\n",
      "\n",
      "[MOBILENET-cam_pro]. Epoch [1/4], Batch[143/2862] loss: 0.003\n",
      "[MOBILENET-cam_pro]. Epoch [1/4], Batch[286/2862] loss: 0.006\n",
      "[MOBILENET-cam_pro]. Epoch [1/4], Batch[429/2862] loss: 0.007\n",
      "[MOBILENET-cam_pro]. Epoch [1/4], Batch[572/2862] loss: 0.006\n",
      "[MOBILENET-cam_pro]. Epoch [1/4], Batch[715/2862] loss: 0.007\n",
      "[MOBILENET-cam_pro]. Epoch [1/4], Batch[858/2862] loss: 0.007\n",
      "[MOBILENET-cam_pro]. Epoch [1/4], Batch[1001/2862] loss: 0.006\n",
      "[MOBILENET-cam_pro]. Epoch [1/4], Batch[1144/2862] loss: 0.006\n",
      "[MOBILENET-cam_pro]. Epoch [1/4], Batch[1287/2862] loss: 0.006\n",
      "[MOBILENET-cam_pro]. Epoch [1/4], Batch[1430/2862] loss: 0.006\n",
      "[MOBILENET-cam_pro]. Epoch [1/4], Batch[1573/2862] loss: 0.006\n",
      "[MOBILENET-cam_pro]. Epoch [1/4], Batch[1716/2862] loss: 0.006\n",
      "[MOBILENET-cam_pro]. Epoch [1/4], Batch[1859/2862] loss: 0.006\n",
      "[MOBILENET-cam_pro]. Epoch [1/4], Batch[2002/2862] loss: 0.006\n",
      "[MOBILENET-cam_pro]. Epoch [1/4], Batch[2145/2862] loss: 0.006\n",
      "[MOBILENET-cam_pro]. Epoch [1/4], Batch[2288/2862] loss: 0.008\n",
      "[MOBILENET-cam_pro]. Epoch [1/4], Batch[2431/2862] loss: 0.013\n",
      "[MOBILENET-cam_pro]. Epoch [1/4], Batch[2574/2862] loss: 0.015\n",
      "[MOBILENET-cam_pro]. Epoch [1/4], Batch[2717/2862] loss: 0.026\n",
      "[MOBILENET-cam_pro]. Epoch [1/4], Batch[2860/2862] loss: 0.030\n",
      "[MOBILENET-cam_pro]. Epoch [1/4], Batch[2861/2862] loss: 0.030\n",
      "val Loss: 0.0296 Acc: 0.9906\n",
      "New best model found!\n",
      "New record loss: 0.02959384644088389, previous record loss: inf\n",
      "técnica:  gradcam\n",
      "LONGITUD DEL HEATMAPS:  447\n",
      "Técnica:  gradcam\n",
      "técnica:  gradcampp\n",
      "LONGITUD DEL HEATMAPS:  447\n",
      "Técnica:  gradcampp\n",
      "técnica:  smoothgradcampp\n",
      "LONGITUD DEL HEATMAPS:  447\n",
      "Técnica:  smoothgradcampp\n",
      "\n",
      "Epoch 2/4\n",
      "----------\n",
      "[MOBILENET-cam_pro]. Epoch [2/4], Batch[72/1431] loss: 0.009\n",
      "[MOBILENET-cam_pro]. Epoch [2/4], Batch[144/1431] loss: 0.008\n",
      "[MOBILENET-cam_pro]. Epoch [2/4], Batch[216/1431] loss: 0.008\n",
      "[MOBILENET-cam_pro]. Epoch [2/4], Batch[288/1431] loss: 0.008\n",
      "[MOBILENET-cam_pro]. Epoch [2/4], Batch[360/1431] loss: 0.008\n",
      "[MOBILENET-cam_pro]. Epoch [2/4], Batch[432/1431] loss: 0.008\n",
      "[MOBILENET-cam_pro]. Epoch [2/4], Batch[504/1431] loss: 0.008\n",
      "[MOBILENET-cam_pro]. Epoch [2/4], Batch[576/1431] loss: 0.009\n",
      "[MOBILENET-cam_pro]. Epoch [2/4], Batch[648/1431] loss: 0.009\n",
      "[MOBILENET-cam_pro]. Epoch [2/4], Batch[720/1431] loss: 0.009\n",
      "[MOBILENET-cam_pro]. Epoch [2/4], Batch[792/1431] loss: 0.010\n",
      "[MOBILENET-cam_pro]. Epoch [2/4], Batch[864/1431] loss: 0.010\n",
      "[MOBILENET-cam_pro]. Epoch [2/4], Batch[936/1431] loss: 0.010\n",
      "[MOBILENET-cam_pro]. Epoch [2/4], Batch[1008/1431] loss: 0.010\n",
      "[MOBILENET-cam_pro]. Epoch [2/4], Batch[1080/1431] loss: 0.009\n",
      "[MOBILENET-cam_pro]. Epoch [2/4], Batch[1152/1431] loss: 0.009\n",
      "[MOBILENET-cam_pro]. Epoch [2/4], Batch[1224/1431] loss: 0.009\n",
      "[MOBILENET-cam_pro]. Epoch [2/4], Batch[1296/1431] loss: 0.009\n",
      "[MOBILENET-cam_pro]. Epoch [2/4], Batch[1368/1431] loss: 0.009\n",
      "train Loss: 0.0089 Acc: 0.9804\n",
      "\n",
      "[MOBILENET-cam_pro]. Epoch [2/4], Batch[143/2862] loss: 0.001\n",
      "[MOBILENET-cam_pro]. Epoch [2/4], Batch[286/2862] loss: 0.002\n",
      "[MOBILENET-cam_pro]. Epoch [2/4], Batch[429/2862] loss: 0.003\n",
      "[MOBILENET-cam_pro]. Epoch [2/4], Batch[572/2862] loss: 0.002\n",
      "[MOBILENET-cam_pro]. Epoch [2/4], Batch[715/2862] loss: 0.003\n",
      "[MOBILENET-cam_pro]. Epoch [2/4], Batch[858/2862] loss: 0.003\n",
      "[MOBILENET-cam_pro]. Epoch [2/4], Batch[1001/2862] loss: 0.003\n",
      "[MOBILENET-cam_pro]. Epoch [2/4], Batch[1144/2862] loss: 0.003\n",
      "[MOBILENET-cam_pro]. Epoch [2/4], Batch[1287/2862] loss: 0.003\n",
      "[MOBILENET-cam_pro]. Epoch [2/4], Batch[1430/2862] loss: 0.003\n",
      "[MOBILENET-cam_pro]. Epoch [2/4], Batch[1573/2862] loss: 0.004\n",
      "[MOBILENET-cam_pro]. Epoch [2/4], Batch[1716/2862] loss: 0.006\n",
      "[MOBILENET-cam_pro]. Epoch [2/4], Batch[1859/2862] loss: 0.006\n",
      "[MOBILENET-cam_pro]. Epoch [2/4], Batch[2002/2862] loss: 0.006\n",
      "[MOBILENET-cam_pro]. Epoch [2/4], Batch[2145/2862] loss: 0.006\n",
      "[MOBILENET-cam_pro]. Epoch [2/4], Batch[2288/2862] loss: 0.006\n",
      "[MOBILENET-cam_pro]. Epoch [2/4], Batch[2431/2862] loss: 0.007\n",
      "[MOBILENET-cam_pro]. Epoch [2/4], Batch[2574/2862] loss: 0.008\n",
      "[MOBILENET-cam_pro]. Epoch [2/4], Batch[2717/2862] loss: 0.015\n",
      "[MOBILENET-cam_pro]. Epoch [2/4], Batch[2860/2862] loss: 0.015\n",
      "[MOBILENET-cam_pro]. Epoch [2/4], Batch[2861/2862] loss: 0.015\n",
      "val Loss: 0.0154 Acc: 0.9955\n",
      "New best model found!\n",
      "New record loss: 0.015425025849881077, previous record loss: 0.02959384644088389\n",
      "técnica:  gradcam\n",
      "LONGITUD DEL HEATMAPS:  447\n",
      "Técnica:  gradcam\n",
      "técnica:  gradcampp\n",
      "LONGITUD DEL HEATMAPS:  447\n",
      "Técnica:  gradcampp\n",
      "técnica:  smoothgradcampp\n",
      "LONGITUD DEL HEATMAPS:  447\n",
      "Técnica:  smoothgradcampp\n",
      "\n",
      "Epoch 3/4\n",
      "----------\n",
      "[MOBILENET-cam_pro]. Epoch [3/4], Batch[72/1431] loss: 0.005\n",
      "[MOBILENET-cam_pro]. Epoch [3/4], Batch[144/1431] loss: 0.008\n",
      "[MOBILENET-cam_pro]. Epoch [3/4], Batch[216/1431] loss: 0.007\n",
      "[MOBILENET-cam_pro]. Epoch [3/4], Batch[288/1431] loss: 0.006\n",
      "[MOBILENET-cam_pro]. Epoch [3/4], Batch[360/1431] loss: 0.007\n",
      "[MOBILENET-cam_pro]. Epoch [3/4], Batch[432/1431] loss: 0.007\n",
      "[MOBILENET-cam_pro]. Epoch [3/4], Batch[504/1431] loss: 0.006\n",
      "[MOBILENET-cam_pro]. Epoch [3/4], Batch[576/1431] loss: 0.007\n",
      "[MOBILENET-cam_pro]. Epoch [3/4], Batch[648/1431] loss: 0.008\n",
      "[MOBILENET-cam_pro]. Epoch [3/4], Batch[720/1431] loss: 0.008\n",
      "[MOBILENET-cam_pro]. Epoch [3/4], Batch[792/1431] loss: 0.007\n",
      "[MOBILENET-cam_pro]. Epoch [3/4], Batch[864/1431] loss: 0.007\n",
      "[MOBILENET-cam_pro]. Epoch [3/4], Batch[936/1431] loss: 0.007\n",
      "[MOBILENET-cam_pro]. Epoch [3/4], Batch[1008/1431] loss: 0.007\n",
      "[MOBILENET-cam_pro]. Epoch [3/4], Batch[1080/1431] loss: 0.007\n",
      "[MOBILENET-cam_pro]. Epoch [3/4], Batch[1152/1431] loss: 0.007\n",
      "[MOBILENET-cam_pro]. Epoch [3/4], Batch[1224/1431] loss: 0.007\n",
      "[MOBILENET-cam_pro]. Epoch [3/4], Batch[1296/1431] loss: 0.007\n",
      "[MOBILENET-cam_pro]. Epoch [3/4], Batch[1368/1431] loss: 0.007\n",
      "train Loss: 0.0066 Acc: 0.9859\n",
      "\n",
      "[MOBILENET-cam_pro]. Epoch [3/4], Batch[143/2862] loss: 0.001\n",
      "[MOBILENET-cam_pro]. Epoch [3/4], Batch[286/2862] loss: 0.003\n",
      "[MOBILENET-cam_pro]. Epoch [3/4], Batch[429/2862] loss: 0.003\n",
      "[MOBILENET-cam_pro]. Epoch [3/4], Batch[572/2862] loss: 0.007\n",
      "[MOBILENET-cam_pro]. Epoch [3/4], Batch[715/2862] loss: 0.012\n",
      "[MOBILENET-cam_pro]. Epoch [3/4], Batch[858/2862] loss: 0.010\n",
      "[MOBILENET-cam_pro]. Epoch [3/4], Batch[1001/2862] loss: 0.009\n",
      "[MOBILENET-cam_pro]. Epoch [3/4], Batch[1144/2862] loss: 0.008\n",
      "[MOBILENET-cam_pro]. Epoch [3/4], Batch[1287/2862] loss: 0.007\n",
      "[MOBILENET-cam_pro]. Epoch [3/4], Batch[1430/2862] loss: 0.007\n",
      "[MOBILENET-cam_pro]. Epoch [3/4], Batch[1573/2862] loss: 0.010\n",
      "[MOBILENET-cam_pro]. Epoch [3/4], Batch[1716/2862] loss: 0.010\n",
      "[MOBILENET-cam_pro]. Epoch [3/4], Batch[1859/2862] loss: 0.014\n",
      "[MOBILENET-cam_pro]. Epoch [3/4], Batch[2002/2862] loss: 0.014\n",
      "[MOBILENET-cam_pro]. Epoch [3/4], Batch[2145/2862] loss: 0.014\n",
      "[MOBILENET-cam_pro]. Epoch [3/4], Batch[2288/2862] loss: 0.013\n",
      "[MOBILENET-cam_pro]. Epoch [3/4], Batch[2431/2862] loss: 0.012\n",
      "[MOBILENET-cam_pro]. Epoch [3/4], Batch[2574/2862] loss: 0.012\n",
      "[MOBILENET-cam_pro]. Epoch [3/4], Batch[2717/2862] loss: 0.012\n",
      "[MOBILENET-cam_pro]. Epoch [3/4], Batch[2860/2862] loss: 0.011\n",
      "[MOBILENET-cam_pro]. Epoch [3/4], Batch[2861/2862] loss: 0.011\n",
      "val Loss: 0.0113 Acc: 0.9976\n",
      "New best model found!\n",
      "New record loss: 0.011324080349217143, previous record loss: 0.015425025849881077\n",
      "técnica:  gradcam\n",
      "LONGITUD DEL HEATMAPS:  447\n",
      "Técnica:  gradcam\n",
      "técnica:  gradcampp\n",
      "LONGITUD DEL HEATMAPS:  447\n",
      "Técnica:  gradcampp\n",
      "técnica:  smoothgradcampp\n",
      "LONGITUD DEL HEATMAPS:  447\n",
      "Técnica:  smoothgradcampp\n",
      "\n",
      "Epoch 4/4\n",
      "----------\n",
      "[MOBILENET-cam_pro]. Epoch [4/4], Batch[72/1431] loss: 0.005\n",
      "[MOBILENET-cam_pro]. Epoch [4/4], Batch[144/1431] loss: 0.006\n",
      "[MOBILENET-cam_pro]. Epoch [4/4], Batch[216/1431] loss: 0.006\n",
      "[MOBILENET-cam_pro]. Epoch [4/4], Batch[288/1431] loss: 0.006\n",
      "[MOBILENET-cam_pro]. Epoch [4/4], Batch[360/1431] loss: 0.006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MOBILENET-cam_pro]. Epoch [4/4], Batch[432/1431] loss: 0.006\n",
      "[MOBILENET-cam_pro]. Epoch [4/4], Batch[504/1431] loss: 0.006\n",
      "[MOBILENET-cam_pro]. Epoch [4/4], Batch[576/1431] loss: 0.006\n",
      "[MOBILENET-cam_pro]. Epoch [4/4], Batch[648/1431] loss: 0.006\n",
      "[MOBILENET-cam_pro]. Epoch [4/4], Batch[720/1431] loss: 0.006\n",
      "[MOBILENET-cam_pro]. Epoch [4/4], Batch[792/1431] loss: 0.006\n",
      "[MOBILENET-cam_pro]. Epoch [4/4], Batch[864/1431] loss: 0.006\n",
      "[MOBILENET-cam_pro]. Epoch [4/4], Batch[936/1431] loss: 0.006\n",
      "[MOBILENET-cam_pro]. Epoch [4/4], Batch[1008/1431] loss: 0.006\n",
      "[MOBILENET-cam_pro]. Epoch [4/4], Batch[1080/1431] loss: 0.006\n",
      "[MOBILENET-cam_pro]. Epoch [4/4], Batch[1152/1431] loss: 0.006\n",
      "[MOBILENET-cam_pro]. Epoch [4/4], Batch[1224/1431] loss: 0.006\n",
      "[MOBILENET-cam_pro]. Epoch [4/4], Batch[1296/1431] loss: 0.006\n",
      "[MOBILENET-cam_pro]. Epoch [4/4], Batch[1368/1431] loss: 0.007\n",
      "train Loss: 0.0066 Acc: 0.9851\n",
      "\n",
      "[MOBILENET-cam_pro]. Epoch [4/4], Batch[143/2862] loss: 0.014\n",
      "[MOBILENET-cam_pro]. Epoch [4/4], Batch[286/2862] loss: 0.016\n",
      "[MOBILENET-cam_pro]. Epoch [4/4], Batch[429/2862] loss: 0.016\n",
      "[MOBILENET-cam_pro]. Epoch [4/4], Batch[572/2862] loss: 0.013\n",
      "[MOBILENET-cam_pro]. Epoch [4/4], Batch[715/2862] loss: 0.015\n",
      "[MOBILENET-cam_pro]. Epoch [4/4], Batch[858/2862] loss: 0.013\n",
      "[MOBILENET-cam_pro]. Epoch [4/4], Batch[1001/2862] loss: 0.011\n",
      "[MOBILENET-cam_pro]. Epoch [4/4], Batch[1144/2862] loss: 0.012\n",
      "[MOBILENET-cam_pro]. Epoch [4/4], Batch[1287/2862] loss: 0.012\n",
      "[MOBILENET-cam_pro]. Epoch [4/4], Batch[1430/2862] loss: 0.011\n",
      "[MOBILENET-cam_pro]. Epoch [4/4], Batch[1573/2862] loss: 0.016\n",
      "[MOBILENET-cam_pro]. Epoch [4/4], Batch[1716/2862] loss: 0.015\n",
      "[MOBILENET-cam_pro]. Epoch [4/4], Batch[1859/2862] loss: 0.014\n",
      "[MOBILENET-cam_pro]. Epoch [4/4], Batch[2002/2862] loss: 0.013\n",
      "[MOBILENET-cam_pro]. Epoch [4/4], Batch[2145/2862] loss: 0.012\n",
      "[MOBILENET-cam_pro]. Epoch [4/4], Batch[2288/2862] loss: 0.013\n",
      "[MOBILENET-cam_pro]. Epoch [4/4], Batch[2431/2862] loss: 0.016\n",
      "[MOBILENET-cam_pro]. Epoch [4/4], Batch[2574/2862] loss: 0.016\n",
      "[MOBILENET-cam_pro]. Epoch [4/4], Batch[2717/2862] loss: 0.020\n",
      "[MOBILENET-cam_pro]. Epoch [4/4], Batch[2860/2862] loss: 0.019\n",
      "[MOBILENET-cam_pro]. Epoch [4/4], Batch[2861/2862] loss: 0.019\n",
      "val Loss: 0.0193 Acc: 0.9937\n",
      "\n",
      "Training complete in 16m 46s\n",
      "Best val Acc: 0.9976 Best val loss: 0.0113\n",
      "model_MOBILENET-cam_pro guardado\n",
      "Clases:  ['Benign', 'Pathological']\n",
      "Train image size: 11454\n",
      "Validation image size: 2862\n",
      "Test image size: 7336\n",
      "Dataset loaded.\n",
      "\n",
      "\n",
      " CAM\n",
      "model_efficientnet-cam not found\n",
      "Epoch 1/4\n",
      "----------\n",
      "[EFFICIENTNET-cam]. Epoch [1/4], Batch[72/1431] loss: 0.059\n",
      "[EFFICIENTNET-cam]. Epoch [1/4], Batch[144/1431] loss: 0.050\n",
      "[EFFICIENTNET-cam]. Epoch [1/4], Batch[216/1431] loss: 0.046\n",
      "[EFFICIENTNET-cam]. Epoch [1/4], Batch[288/1431] loss: 0.043\n",
      "[EFFICIENTNET-cam]. Epoch [1/4], Batch[360/1431] loss: 0.040\n",
      "[EFFICIENTNET-cam]. Epoch [1/4], Batch[432/1431] loss: 0.038\n",
      "[EFFICIENTNET-cam]. Epoch [1/4], Batch[504/1431] loss: 0.036\n",
      "[EFFICIENTNET-cam]. Epoch [1/4], Batch[576/1431] loss: 0.034\n",
      "[EFFICIENTNET-cam]. Epoch [1/4], Batch[648/1431] loss: 0.033\n",
      "[EFFICIENTNET-cam]. Epoch [1/4], Batch[720/1431] loss: 0.032\n",
      "[EFFICIENTNET-cam]. Epoch [1/4], Batch[792/1431] loss: 0.031\n",
      "[EFFICIENTNET-cam]. Epoch [1/4], Batch[864/1431] loss: 0.030\n",
      "[EFFICIENTNET-cam]. Epoch [1/4], Batch[936/1431] loss: 0.029\n",
      "[EFFICIENTNET-cam]. Epoch [1/4], Batch[1008/1431] loss: 0.028\n",
      "[EFFICIENTNET-cam]. Epoch [1/4], Batch[1080/1431] loss: 0.027\n",
      "[EFFICIENTNET-cam]. Epoch [1/4], Batch[1152/1431] loss: 0.026\n",
      "[EFFICIENTNET-cam]. Epoch [1/4], Batch[1224/1431] loss: 0.026\n",
      "[EFFICIENTNET-cam]. Epoch [1/4], Batch[1296/1431] loss: 0.025\n",
      "[EFFICIENTNET-cam]. Epoch [1/4], Batch[1368/1431] loss: 0.024\n",
      "train Loss: 0.0237 Acc: 0.9271\n",
      "\n",
      "[EFFICIENTNET-cam]. Epoch [1/4], Batch[143/2862] loss: 0.039\n",
      "[EFFICIENTNET-cam]. Epoch [1/4], Batch[286/2862] loss: 0.105\n",
      "[EFFICIENTNET-cam]. Epoch [1/4], Batch[429/2862] loss: 0.122\n",
      "[EFFICIENTNET-cam]. Epoch [1/4], Batch[572/2862] loss: 0.102\n",
      "[EFFICIENTNET-cam]. Epoch [1/4], Batch[715/2862] loss: 0.095\n",
      "[EFFICIENTNET-cam]. Epoch [1/4], Batch[858/2862] loss: 0.083\n",
      "[EFFICIENTNET-cam]. Epoch [1/4], Batch[1001/2862] loss: 0.076\n",
      "[EFFICIENTNET-cam]. Epoch [1/4], Batch[1144/2862] loss: 0.089\n",
      "[EFFICIENTNET-cam]. Epoch [1/4], Batch[1287/2862] loss: 0.088\n",
      "[EFFICIENTNET-cam]. Epoch [1/4], Batch[1430/2862] loss: 0.087\n",
      "[EFFICIENTNET-cam]. Epoch [1/4], Batch[1573/2862] loss: 0.083\n",
      "[EFFICIENTNET-cam]. Epoch [1/4], Batch[1716/2862] loss: 0.086\n",
      "[EFFICIENTNET-cam]. Epoch [1/4], Batch[1859/2862] loss: 0.085\n",
      "[EFFICIENTNET-cam]. Epoch [1/4], Batch[2002/2862] loss: 0.083\n",
      "[EFFICIENTNET-cam]. Epoch [1/4], Batch[2145/2862] loss: 0.080\n",
      "[EFFICIENTNET-cam]. Epoch [1/4], Batch[2288/2862] loss: 0.077\n",
      "[EFFICIENTNET-cam]. Epoch [1/4], Batch[2431/2862] loss: 0.075\n",
      "[EFFICIENTNET-cam]. Epoch [1/4], Batch[2574/2862] loss: 0.072\n",
      "[EFFICIENTNET-cam]. Epoch [1/4], Batch[2717/2862] loss: 0.073\n",
      "[EFFICIENTNET-cam]. Epoch [1/4], Batch[2860/2862] loss: 0.073\n",
      "[EFFICIENTNET-cam]. Epoch [1/4], Batch[2861/2862] loss: 0.073\n",
      "val Loss: 0.0733 Acc: 0.9731\n",
      "New best model found!\n",
      "New record loss: 0.07333262592402065, previous record loss: inf\n",
      "técnica:  cam\n",
      "LONGITUD DEL HEATMAPS:  447\n",
      "Técnica:  cam\n",
      "\n",
      "Epoch 2/4\n",
      "----------\n",
      "[EFFICIENTNET-cam]. Epoch [2/4], Batch[72/1431] loss: 0.011\n",
      "[EFFICIENTNET-cam]. Epoch [2/4], Batch[144/1431] loss: 0.010\n",
      "[EFFICIENTNET-cam]. Epoch [2/4], Batch[216/1431] loss: 0.012\n",
      "[EFFICIENTNET-cam]. Epoch [2/4], Batch[288/1431] loss: 0.012\n",
      "[EFFICIENTNET-cam]. Epoch [2/4], Batch[360/1431] loss: 0.011\n",
      "[EFFICIENTNET-cam]. Epoch [2/4], Batch[432/1431] loss: 0.011\n",
      "[EFFICIENTNET-cam]. Epoch [2/4], Batch[504/1431] loss: 0.011\n",
      "[EFFICIENTNET-cam]. Epoch [2/4], Batch[576/1431] loss: 0.011\n",
      "[EFFICIENTNET-cam]. Epoch [2/4], Batch[648/1431] loss: 0.011\n",
      "[EFFICIENTNET-cam]. Epoch [2/4], Batch[720/1431] loss: 0.011\n",
      "[EFFICIENTNET-cam]. Epoch [2/4], Batch[792/1431] loss: 0.011\n",
      "[EFFICIENTNET-cam]. Epoch [2/4], Batch[864/1431] loss: 0.011\n",
      "[EFFICIENTNET-cam]. Epoch [2/4], Batch[936/1431] loss: 0.011\n",
      "[EFFICIENTNET-cam]. Epoch [2/4], Batch[1008/1431] loss: 0.011\n",
      "[EFFICIENTNET-cam]. Epoch [2/4], Batch[1080/1431] loss: 0.011\n",
      "[EFFICIENTNET-cam]. Epoch [2/4], Batch[1152/1431] loss: 0.011\n",
      "[EFFICIENTNET-cam]. Epoch [2/4], Batch[1224/1431] loss: 0.011\n",
      "[EFFICIENTNET-cam]. Epoch [2/4], Batch[1296/1431] loss: 0.010\n",
      "[EFFICIENTNET-cam]. Epoch [2/4], Batch[1368/1431] loss: 0.010\n",
      "train Loss: 0.0103 Acc: 0.9703\n",
      "\n",
      "[EFFICIENTNET-cam]. Epoch [2/4], Batch[143/2862] loss: 0.006\n",
      "[EFFICIENTNET-cam]. Epoch [2/4], Batch[286/2862] loss: 0.027\n",
      "[EFFICIENTNET-cam]. Epoch [2/4], Batch[429/2862] loss: 0.025\n",
      "[EFFICIENTNET-cam]. Epoch [2/4], Batch[572/2862] loss: 0.020\n",
      "[EFFICIENTNET-cam]. Epoch [2/4], Batch[715/2862] loss: 0.019\n",
      "[EFFICIENTNET-cam]. Epoch [2/4], Batch[858/2862] loss: 0.016\n",
      "[EFFICIENTNET-cam]. Epoch [2/4], Batch[1001/2862] loss: 0.014\n",
      "[EFFICIENTNET-cam]. Epoch [2/4], Batch[1144/2862] loss: 0.018\n",
      "[EFFICIENTNET-cam]. Epoch [2/4], Batch[1287/2862] loss: 0.017\n",
      "[EFFICIENTNET-cam]. Epoch [2/4], Batch[1430/2862] loss: 0.017\n",
      "[EFFICIENTNET-cam]. Epoch [2/4], Batch[1573/2862] loss: 0.016\n",
      "[EFFICIENTNET-cam]. Epoch [2/4], Batch[1716/2862] loss: 0.016\n",
      "[EFFICIENTNET-cam]. Epoch [2/4], Batch[1859/2862] loss: 0.017\n",
      "[EFFICIENTNET-cam]. Epoch [2/4], Batch[2002/2862] loss: 0.016\n",
      "[EFFICIENTNET-cam]. Epoch [2/4], Batch[2145/2862] loss: 0.016\n",
      "[EFFICIENTNET-cam]. Epoch [2/4], Batch[2288/2862] loss: 0.016\n",
      "[EFFICIENTNET-cam]. Epoch [2/4], Batch[2431/2862] loss: 0.018\n",
      "[EFFICIENTNET-cam]. Epoch [2/4], Batch[2574/2862] loss: 0.018\n",
      "[EFFICIENTNET-cam]. Epoch [2/4], Batch[2717/2862] loss: 0.024\n",
      "[EFFICIENTNET-cam]. Epoch [2/4], Batch[2860/2862] loss: 0.027\n",
      "[EFFICIENTNET-cam]. Epoch [2/4], Batch[2861/2862] loss: 0.027\n",
      "val Loss: 0.0274 Acc: 0.9923\n",
      "New best model found!\n",
      "New record loss: 0.027424113994598105, previous record loss: 0.07333262592402065\n",
      "técnica:  cam\n",
      "LONGITUD DEL HEATMAPS:  447\n",
      "Técnica:  cam\n",
      "\n",
      "Epoch 3/4\n",
      "----------\n",
      "[EFFICIENTNET-cam]. Epoch [3/4], Batch[72/1431] loss: 0.008\n",
      "[EFFICIENTNET-cam]. Epoch [3/4], Batch[144/1431] loss: 0.008\n",
      "[EFFICIENTNET-cam]. Epoch [3/4], Batch[216/1431] loss: 0.009\n",
      "[EFFICIENTNET-cam]. Epoch [3/4], Batch[288/1431] loss: 0.008\n",
      "[EFFICIENTNET-cam]. Epoch [3/4], Batch[360/1431] loss: 0.008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EFFICIENTNET-cam]. Epoch [3/4], Batch[432/1431] loss: 0.008\n",
      "[EFFICIENTNET-cam]. Epoch [3/4], Batch[504/1431] loss: 0.008\n",
      "[EFFICIENTNET-cam]. Epoch [3/4], Batch[576/1431] loss: 0.008\n",
      "[EFFICIENTNET-cam]. Epoch [3/4], Batch[648/1431] loss: 0.008\n",
      "[EFFICIENTNET-cam]. Epoch [3/4], Batch[720/1431] loss: 0.007\n",
      "[EFFICIENTNET-cam]. Epoch [3/4], Batch[792/1431] loss: 0.007\n",
      "[EFFICIENTNET-cam]. Epoch [3/4], Batch[864/1431] loss: 0.007\n",
      "[EFFICIENTNET-cam]. Epoch [3/4], Batch[936/1431] loss: 0.007\n",
      "[EFFICIENTNET-cam]. Epoch [3/4], Batch[1008/1431] loss: 0.007\n",
      "[EFFICIENTNET-cam]. Epoch [3/4], Batch[1080/1431] loss: 0.007\n",
      "[EFFICIENTNET-cam]. Epoch [3/4], Batch[1152/1431] loss: 0.007\n",
      "[EFFICIENTNET-cam]. Epoch [3/4], Batch[1224/1431] loss: 0.007\n",
      "[EFFICIENTNET-cam]. Epoch [3/4], Batch[1296/1431] loss: 0.007\n",
      "[EFFICIENTNET-cam]. Epoch [3/4], Batch[1368/1431] loss: 0.007\n",
      "train Loss: 0.0069 Acc: 0.9812\n",
      "\n",
      "[EFFICIENTNET-cam]. Epoch [3/4], Batch[143/2862] loss: 0.007\n",
      "[EFFICIENTNET-cam]. Epoch [3/4], Batch[286/2862] loss: 0.022\n",
      "[EFFICIENTNET-cam]. Epoch [3/4], Batch[429/2862] loss: 0.017\n",
      "[EFFICIENTNET-cam]. Epoch [3/4], Batch[572/2862] loss: 0.014\n",
      "[EFFICIENTNET-cam]. Epoch [3/4], Batch[715/2862] loss: 0.012\n",
      "[EFFICIENTNET-cam]. Epoch [3/4], Batch[858/2862] loss: 0.010\n",
      "[EFFICIENTNET-cam]. Epoch [3/4], Batch[1001/2862] loss: 0.009\n",
      "[EFFICIENTNET-cam]. Epoch [3/4], Batch[1144/2862] loss: 0.010\n",
      "[EFFICIENTNET-cam]. Epoch [3/4], Batch[1287/2862] loss: 0.009\n",
      "[EFFICIENTNET-cam]. Epoch [3/4], Batch[1430/2862] loss: 0.009\n",
      "[EFFICIENTNET-cam]. Epoch [3/4], Batch[1573/2862] loss: 0.009\n",
      "[EFFICIENTNET-cam]. Epoch [3/4], Batch[1716/2862] loss: 0.009\n",
      "[EFFICIENTNET-cam]. Epoch [3/4], Batch[1859/2862] loss: 0.010\n",
      "[EFFICIENTNET-cam]. Epoch [3/4], Batch[2002/2862] loss: 0.009\n",
      "[EFFICIENTNET-cam]. Epoch [3/4], Batch[2145/2862] loss: 0.009\n",
      "[EFFICIENTNET-cam]. Epoch [3/4], Batch[2288/2862] loss: 0.009\n",
      "[EFFICIENTNET-cam]. Epoch [3/4], Batch[2431/2862] loss: 0.011\n",
      "[EFFICIENTNET-cam]. Epoch [3/4], Batch[2574/2862] loss: 0.012\n",
      "[EFFICIENTNET-cam]. Epoch [3/4], Batch[2717/2862] loss: 0.017\n",
      "[EFFICIENTNET-cam]. Epoch [3/4], Batch[2860/2862] loss: 0.019\n",
      "[EFFICIENTNET-cam]. Epoch [3/4], Batch[2861/2862] loss: 0.019\n",
      "val Loss: 0.0192 Acc: 0.9951\n",
      "New best model found!\n",
      "New record loss: 0.019241833356137536, previous record loss: 0.027424113994598105\n",
      "técnica:  cam\n",
      "LONGITUD DEL HEATMAPS:  447\n",
      "Técnica:  cam\n",
      "\n",
      "Epoch 4/4\n",
      "----------\n",
      "[EFFICIENTNET-cam]. Epoch [4/4], Batch[72/1431] loss: 0.004\n",
      "[EFFICIENTNET-cam]. Epoch [4/4], Batch[144/1431] loss: 0.004\n",
      "[EFFICIENTNET-cam]. Epoch [4/4], Batch[216/1431] loss: 0.005\n",
      "[EFFICIENTNET-cam]. Epoch [4/4], Batch[288/1431] loss: 0.004\n",
      "[EFFICIENTNET-cam]. Epoch [4/4], Batch[360/1431] loss: 0.005\n",
      "[EFFICIENTNET-cam]. Epoch [4/4], Batch[432/1431] loss: 0.004\n",
      "[EFFICIENTNET-cam]. Epoch [4/4], Batch[504/1431] loss: 0.004\n",
      "[EFFICIENTNET-cam]. Epoch [4/4], Batch[576/1431] loss: 0.005\n",
      "[EFFICIENTNET-cam]. Epoch [4/4], Batch[648/1431] loss: 0.005\n",
      "[EFFICIENTNET-cam]. Epoch [4/4], Batch[720/1431] loss: 0.005\n",
      "[EFFICIENTNET-cam]. Epoch [4/4], Batch[792/1431] loss: 0.005\n",
      "[EFFICIENTNET-cam]. Epoch [4/4], Batch[864/1431] loss: 0.005\n",
      "[EFFICIENTNET-cam]. Epoch [4/4], Batch[936/1431] loss: 0.005\n",
      "[EFFICIENTNET-cam]. Epoch [4/4], Batch[1008/1431] loss: 0.005\n",
      "[EFFICIENTNET-cam]. Epoch [4/4], Batch[1080/1431] loss: 0.005\n",
      "[EFFICIENTNET-cam]. Epoch [4/4], Batch[1152/1431] loss: 0.005\n",
      "[EFFICIENTNET-cam]. Epoch [4/4], Batch[1224/1431] loss: 0.005\n",
      "[EFFICIENTNET-cam]. Epoch [4/4], Batch[1296/1431] loss: 0.005\n",
      "[EFFICIENTNET-cam]. Epoch [4/4], Batch[1368/1431] loss: 0.005\n",
      "train Loss: 0.0045 Acc: 0.9875\n",
      "\n",
      "[EFFICIENTNET-cam]. Epoch [4/4], Batch[143/2862] loss: 0.027\n",
      "[EFFICIENTNET-cam]. Epoch [4/4], Batch[286/2862] loss: 0.053\n",
      "[EFFICIENTNET-cam]. Epoch [4/4], Batch[429/2862] loss: 0.059\n",
      "[EFFICIENTNET-cam]. Epoch [4/4], Batch[572/2862] loss: 0.048\n",
      "[EFFICIENTNET-cam]. Epoch [4/4], Batch[715/2862] loss: 0.042\n",
      "[EFFICIENTNET-cam]. Epoch [4/4], Batch[858/2862] loss: 0.036\n",
      "[EFFICIENTNET-cam]. Epoch [4/4], Batch[1001/2862] loss: 0.033\n",
      "[EFFICIENTNET-cam]. Epoch [4/4], Batch[1144/2862] loss: 0.035\n",
      "[EFFICIENTNET-cam]. Epoch [4/4], Batch[1287/2862] loss: 0.034\n",
      "[EFFICIENTNET-cam]. Epoch [4/4], Batch[1430/2862] loss: 0.035\n",
      "[EFFICIENTNET-cam]. Epoch [4/4], Batch[1573/2862] loss: 0.037\n",
      "[EFFICIENTNET-cam]. Epoch [4/4], Batch[1716/2862] loss: 0.039\n",
      "[EFFICIENTNET-cam]. Epoch [4/4], Batch[1859/2862] loss: 0.039\n",
      "[EFFICIENTNET-cam]. Epoch [4/4], Batch[2002/2862] loss: 0.038\n",
      "[EFFICIENTNET-cam]. Epoch [4/4], Batch[2145/2862] loss: 0.038\n",
      "[EFFICIENTNET-cam]. Epoch [4/4], Batch[2288/2862] loss: 0.036\n",
      "[EFFICIENTNET-cam]. Epoch [4/4], Batch[2431/2862] loss: 0.034\n",
      "[EFFICIENTNET-cam]. Epoch [4/4], Batch[2574/2862] loss: 0.033\n",
      "[EFFICIENTNET-cam]. Epoch [4/4], Batch[2717/2862] loss: 0.033\n",
      "[EFFICIENTNET-cam]. Epoch [4/4], Batch[2860/2862] loss: 0.032\n",
      "[EFFICIENTNET-cam]. Epoch [4/4], Batch[2861/2862] loss: 0.032\n",
      "val Loss: 0.0319 Acc: 0.9885\n",
      "\n",
      "Training complete in 6m 48s\n",
      "Best val Acc: 0.9951 Best val loss: 0.0192\n",
      "model_EFFICIENTNET-cam guardado\n",
      "Clases:  ['Benign', 'Pathological']\n",
      "Train image size: 11454\n",
      "Validation image size: 2862\n",
      "Test image size: 7336\n",
      "Dataset loaded.\n",
      "\n",
      "\n",
      " CAM_PRO\n",
      "model_efficientnet-cam_pro not found\n",
      "Epoch 1/4\n",
      "----------\n",
      "[EFFICIENTNET-cam_pro]. Epoch [1/4], Batch[72/1431] loss: 0.084\n",
      "[EFFICIENTNET-cam_pro]. Epoch [1/4], Batch[144/1431] loss: 0.071\n",
      "[EFFICIENTNET-cam_pro]. Epoch [1/4], Batch[216/1431] loss: 0.061\n",
      "[EFFICIENTNET-cam_pro]. Epoch [1/4], Batch[288/1431] loss: 0.054\n",
      "[EFFICIENTNET-cam_pro]. Epoch [1/4], Batch[360/1431] loss: 0.049\n",
      "[EFFICIENTNET-cam_pro]. Epoch [1/4], Batch[432/1431] loss: 0.045\n",
      "[EFFICIENTNET-cam_pro]. Epoch [1/4], Batch[504/1431] loss: 0.041\n",
      "[EFFICIENTNET-cam_pro]. Epoch [1/4], Batch[576/1431] loss: 0.038\n",
      "[EFFICIENTNET-cam_pro]. Epoch [1/4], Batch[648/1431] loss: 0.036\n",
      "[EFFICIENTNET-cam_pro]. Epoch [1/4], Batch[720/1431] loss: 0.034\n",
      "[EFFICIENTNET-cam_pro]. Epoch [1/4], Batch[792/1431] loss: 0.032\n",
      "[EFFICIENTNET-cam_pro]. Epoch [1/4], Batch[864/1431] loss: 0.031\n",
      "[EFFICIENTNET-cam_pro]. Epoch [1/4], Batch[936/1431] loss: 0.029\n",
      "[EFFICIENTNET-cam_pro]. Epoch [1/4], Batch[1008/1431] loss: 0.027\n",
      "[EFFICIENTNET-cam_pro]. Epoch [1/4], Batch[1080/1431] loss: 0.026\n",
      "[EFFICIENTNET-cam_pro]. Epoch [1/4], Batch[1152/1431] loss: 0.025\n",
      "[EFFICIENTNET-cam_pro]. Epoch [1/4], Batch[1224/1431] loss: 0.025\n",
      "[EFFICIENTNET-cam_pro]. Epoch [1/4], Batch[1296/1431] loss: 0.024\n",
      "[EFFICIENTNET-cam_pro]. Epoch [1/4], Batch[1368/1431] loss: 0.023\n",
      "train Loss: 0.0223 Acc: 0.9211\n",
      "\n",
      "[EFFICIENTNET-cam_pro]. Epoch [1/4], Batch[143/2862] loss: 0.008\n",
      "[EFFICIENTNET-cam_pro]. Epoch [1/4], Batch[286/2862] loss: 0.035\n",
      "[EFFICIENTNET-cam_pro]. Epoch [1/4], Batch[429/2862] loss: 0.049\n",
      "[EFFICIENTNET-cam_pro]. Epoch [1/4], Batch[572/2862] loss: 0.040\n",
      "[EFFICIENTNET-cam_pro]. Epoch [1/4], Batch[715/2862] loss: 0.038\n",
      "[EFFICIENTNET-cam_pro]. Epoch [1/4], Batch[858/2862] loss: 0.037\n",
      "[EFFICIENTNET-cam_pro]. Epoch [1/4], Batch[1001/2862] loss: 0.034\n",
      "[EFFICIENTNET-cam_pro]. Epoch [1/4], Batch[1144/2862] loss: 0.035\n",
      "[EFFICIENTNET-cam_pro]. Epoch [1/4], Batch[1287/2862] loss: 0.034\n",
      "[EFFICIENTNET-cam_pro]. Epoch [1/4], Batch[1430/2862] loss: 0.032\n",
      "[EFFICIENTNET-cam_pro]. Epoch [1/4], Batch[1573/2862] loss: 0.034\n",
      "[EFFICIENTNET-cam_pro]. Epoch [1/4], Batch[1716/2862] loss: 0.036\n",
      "[EFFICIENTNET-cam_pro]. Epoch [1/4], Batch[1859/2862] loss: 0.037\n",
      "[EFFICIENTNET-cam_pro]. Epoch [1/4], Batch[2002/2862] loss: 0.039\n",
      "[EFFICIENTNET-cam_pro]. Epoch [1/4], Batch[2145/2862] loss: 0.039\n",
      "[EFFICIENTNET-cam_pro]. Epoch [1/4], Batch[2288/2862] loss: 0.037\n",
      "[EFFICIENTNET-cam_pro]. Epoch [1/4], Batch[2431/2862] loss: 0.036\n",
      "[EFFICIENTNET-cam_pro]. Epoch [1/4], Batch[2574/2862] loss: 0.035\n",
      "[EFFICIENTNET-cam_pro]. Epoch [1/4], Batch[2717/2862] loss: 0.037\n",
      "[EFFICIENTNET-cam_pro]. Epoch [1/4], Batch[2860/2862] loss: 0.036\n",
      "[EFFICIENTNET-cam_pro]. Epoch [1/4], Batch[2861/2862] loss: 0.036\n",
      "val Loss: 0.0355 Acc: 0.9850\n",
      "New best model found!\n",
      "New record loss: 0.03553796685319504, previous record loss: inf\n",
      "técnica:  gradcam\n",
      "LONGITUD DEL HEATMAPS:  447\n",
      "Técnica:  gradcam\n",
      "técnica:  gradcampp\n",
      "LONGITUD DEL HEATMAPS:  447\n",
      "Técnica:  gradcampp\n",
      "técnica:  smoothgradcampp\n",
      "LONGITUD DEL HEATMAPS:  447\n",
      "Técnica:  smoothgradcampp\n",
      "\n",
      "Epoch 2/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EFFICIENTNET-cam_pro]. Epoch [2/4], Batch[72/1431] loss: 0.009\n",
      "[EFFICIENTNET-cam_pro]. Epoch [2/4], Batch[144/1431] loss: 0.008\n",
      "[EFFICIENTNET-cam_pro]. Epoch [2/4], Batch[216/1431] loss: 0.008\n",
      "[EFFICIENTNET-cam_pro]. Epoch [2/4], Batch[288/1431] loss: 0.007\n",
      "[EFFICIENTNET-cam_pro]. Epoch [2/4], Batch[360/1431] loss: 0.007\n",
      "[EFFICIENTNET-cam_pro]. Epoch [2/4], Batch[432/1431] loss: 0.009\n",
      "[EFFICIENTNET-cam_pro]. Epoch [2/4], Batch[504/1431] loss: 0.009\n",
      "[EFFICIENTNET-cam_pro]. Epoch [2/4], Batch[576/1431] loss: 0.009\n",
      "[EFFICIENTNET-cam_pro]. Epoch [2/4], Batch[648/1431] loss: 0.009\n",
      "[EFFICIENTNET-cam_pro]. Epoch [2/4], Batch[720/1431] loss: 0.009\n",
      "[EFFICIENTNET-cam_pro]. Epoch [2/4], Batch[792/1431] loss: 0.008\n",
      "[EFFICIENTNET-cam_pro]. Epoch [2/4], Batch[864/1431] loss: 0.009\n",
      "[EFFICIENTNET-cam_pro]. Epoch [2/4], Batch[936/1431] loss: 0.009\n",
      "[EFFICIENTNET-cam_pro]. Epoch [2/4], Batch[1008/1431] loss: 0.009\n",
      "[EFFICIENTNET-cam_pro]. Epoch [2/4], Batch[1080/1431] loss: 0.009\n",
      "[EFFICIENTNET-cam_pro]. Epoch [2/4], Batch[1152/1431] loss: 0.008\n",
      "[EFFICIENTNET-cam_pro]. Epoch [2/4], Batch[1224/1431] loss: 0.008\n",
      "[EFFICIENTNET-cam_pro]. Epoch [2/4], Batch[1296/1431] loss: 0.008\n",
      "[EFFICIENTNET-cam_pro]. Epoch [2/4], Batch[1368/1431] loss: 0.008\n",
      "train Loss: 0.0083 Acc: 0.9825\n",
      "\n",
      "[EFFICIENTNET-cam_pro]. Epoch [2/4], Batch[143/2862] loss: 0.001\n",
      "[EFFICIENTNET-cam_pro]. Epoch [2/4], Batch[286/2862] loss: 0.001\n",
      "[EFFICIENTNET-cam_pro]. Epoch [2/4], Batch[429/2862] loss: 0.001\n",
      "[EFFICIENTNET-cam_pro]. Epoch [2/4], Batch[572/2862] loss: 0.001\n",
      "[EFFICIENTNET-cam_pro]. Epoch [2/4], Batch[715/2862] loss: 0.001\n",
      "[EFFICIENTNET-cam_pro]. Epoch [2/4], Batch[858/2862] loss: 0.000\n",
      "[EFFICIENTNET-cam_pro]. Epoch [2/4], Batch[1001/2862] loss: 0.000\n",
      "[EFFICIENTNET-cam_pro]. Epoch [2/4], Batch[1144/2862] loss: 0.002\n",
      "[EFFICIENTNET-cam_pro]. Epoch [2/4], Batch[1287/2862] loss: 0.002\n",
      "[EFFICIENTNET-cam_pro]. Epoch [2/4], Batch[1430/2862] loss: 0.002\n",
      "[EFFICIENTNET-cam_pro]. Epoch [2/4], Batch[1573/2862] loss: 0.002\n",
      "[EFFICIENTNET-cam_pro]. Epoch [2/4], Batch[1716/2862] loss: 0.003\n",
      "[EFFICIENTNET-cam_pro]. Epoch [2/4], Batch[1859/2862] loss: 0.004\n",
      "[EFFICIENTNET-cam_pro]. Epoch [2/4], Batch[2002/2862] loss: 0.004\n",
      "[EFFICIENTNET-cam_pro]. Epoch [2/4], Batch[2145/2862] loss: 0.003\n",
      "[EFFICIENTNET-cam_pro]. Epoch [2/4], Batch[2288/2862] loss: 0.003\n",
      "[EFFICIENTNET-cam_pro]. Epoch [2/4], Batch[2431/2862] loss: 0.012\n",
      "[EFFICIENTNET-cam_pro]. Epoch [2/4], Batch[2574/2862] loss: 0.014\n",
      "[EFFICIENTNET-cam_pro]. Epoch [2/4], Batch[2717/2862] loss: 0.029\n",
      "[EFFICIENTNET-cam_pro]. Epoch [2/4], Batch[2860/2862] loss: 0.031\n",
      "[EFFICIENTNET-cam_pro]. Epoch [2/4], Batch[2861/2862] loss: 0.031\n",
      "val Loss: 0.0314 Acc: 0.9906\n",
      "New best model found!\n",
      "New record loss: 0.031361723346878215, previous record loss: 0.03553796685319504\n",
      "técnica:  gradcam\n",
      "LONGITUD DEL HEATMAPS:  447\n",
      "Técnica:  gradcam\n",
      "técnica:  gradcampp\n",
      "LONGITUD DEL HEATMAPS:  447\n",
      "Técnica:  gradcampp\n",
      "técnica:  smoothgradcampp\n",
      "LONGITUD DEL HEATMAPS:  447\n",
      "Técnica:  smoothgradcampp\n",
      "\n",
      "Epoch 3/4\n",
      "----------\n",
      "[EFFICIENTNET-cam_pro]. Epoch [3/4], Batch[72/1431] loss: 0.007\n",
      "[EFFICIENTNET-cam_pro]. Epoch [3/4], Batch[144/1431] loss: 0.007\n",
      "[EFFICIENTNET-cam_pro]. Epoch [3/4], Batch[216/1431] loss: 0.006\n",
      "[EFFICIENTNET-cam_pro]. Epoch [3/4], Batch[288/1431] loss: 0.006\n",
      "[EFFICIENTNET-cam_pro]. Epoch [3/4], Batch[360/1431] loss: 0.006\n",
      "[EFFICIENTNET-cam_pro]. Epoch [3/4], Batch[432/1431] loss: 0.006\n",
      "[EFFICIENTNET-cam_pro]. Epoch [3/4], Batch[504/1431] loss: 0.006\n",
      "[EFFICIENTNET-cam_pro]. Epoch [3/4], Batch[576/1431] loss: 0.006\n",
      "[EFFICIENTNET-cam_pro]. Epoch [3/4], Batch[648/1431] loss: 0.006\n",
      "[EFFICIENTNET-cam_pro]. Epoch [3/4], Batch[720/1431] loss: 0.006\n",
      "[EFFICIENTNET-cam_pro]. Epoch [3/4], Batch[792/1431] loss: 0.006\n",
      "[EFFICIENTNET-cam_pro]. Epoch [3/4], Batch[864/1431] loss: 0.006\n",
      "[EFFICIENTNET-cam_pro]. Epoch [3/4], Batch[936/1431] loss: 0.006\n",
      "[EFFICIENTNET-cam_pro]. Epoch [3/4], Batch[1008/1431] loss: 0.006\n",
      "[EFFICIENTNET-cam_pro]. Epoch [3/4], Batch[1080/1431] loss: 0.006\n",
      "[EFFICIENTNET-cam_pro]. Epoch [3/4], Batch[1152/1431] loss: 0.006\n",
      "[EFFICIENTNET-cam_pro]. Epoch [3/4], Batch[1224/1431] loss: 0.006\n",
      "[EFFICIENTNET-cam_pro]. Epoch [3/4], Batch[1296/1431] loss: 0.006\n",
      "[EFFICIENTNET-cam_pro]. Epoch [3/4], Batch[1368/1431] loss: 0.006\n",
      "train Loss: 0.0057 Acc: 0.9887\n",
      "\n",
      "[EFFICIENTNET-cam_pro]. Epoch [3/4], Batch[143/2862] loss: 0.015\n",
      "[EFFICIENTNET-cam_pro]. Epoch [3/4], Batch[286/2862] loss: 0.029\n",
      "[EFFICIENTNET-cam_pro]. Epoch [3/4], Batch[429/2862] loss: 0.026\n",
      "[EFFICIENTNET-cam_pro]. Epoch [3/4], Batch[572/2862] loss: 0.020\n",
      "[EFFICIENTNET-cam_pro]. Epoch [3/4], Batch[715/2862] loss: 0.019\n",
      "[EFFICIENTNET-cam_pro]. Epoch [3/4], Batch[858/2862] loss: 0.016\n",
      "[EFFICIENTNET-cam_pro]. Epoch [3/4], Batch[1001/2862] loss: 0.014\n",
      "[EFFICIENTNET-cam_pro]. Epoch [3/4], Batch[1144/2862] loss: 0.014\n",
      "[EFFICIENTNET-cam_pro]. Epoch [3/4], Batch[1287/2862] loss: 0.015\n",
      "[EFFICIENTNET-cam_pro]. Epoch [3/4], Batch[1430/2862] loss: 0.013\n",
      "[EFFICIENTNET-cam_pro]. Epoch [3/4], Batch[1573/2862] loss: 0.013\n",
      "[EFFICIENTNET-cam_pro]. Epoch [3/4], Batch[1716/2862] loss: 0.015\n",
      "[EFFICIENTNET-cam_pro]. Epoch [3/4], Batch[1859/2862] loss: 0.015\n",
      "[EFFICIENTNET-cam_pro]. Epoch [3/4], Batch[2002/2862] loss: 0.014\n",
      "[EFFICIENTNET-cam_pro]. Epoch [3/4], Batch[2145/2862] loss: 0.014\n",
      "[EFFICIENTNET-cam_pro]. Epoch [3/4], Batch[2288/2862] loss: 0.013\n",
      "[EFFICIENTNET-cam_pro]. Epoch [3/4], Batch[2431/2862] loss: 0.013\n",
      "[EFFICIENTNET-cam_pro]. Epoch [3/4], Batch[2574/2862] loss: 0.013\n",
      "[EFFICIENTNET-cam_pro]. Epoch [3/4], Batch[2717/2862] loss: 0.013\n",
      "[EFFICIENTNET-cam_pro]. Epoch [3/4], Batch[2860/2862] loss: 0.015\n",
      "[EFFICIENTNET-cam_pro]. Epoch [3/4], Batch[2861/2862] loss: 0.015\n",
      "val Loss: 0.0154 Acc: 0.9944\n",
      "New best model found!\n",
      "New record loss: 0.015352799105964892, previous record loss: 0.031361723346878215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pedro\\Documents\\TFG\\TFG\\src\\utils.py:68: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axes = plt.subplots(nrows=1,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "técnica:  gradcam\n",
      "LONGITUD DEL HEATMAPS:  447\n",
      "Técnica:  gradcam\n",
      "técnica:  gradcampp\n",
      "LONGITUD DEL HEATMAPS:  447\n",
      "Técnica:  gradcampp\n",
      "técnica:  smoothgradcampp\n",
      "LONGITUD DEL HEATMAPS:  447\n",
      "Técnica:  smoothgradcampp\n",
      "\n",
      "Epoch 4/4\n",
      "----------\n",
      "[EFFICIENTNET-cam_pro]. Epoch [4/4], Batch[72/1431] loss: 0.004\n",
      "[EFFICIENTNET-cam_pro]. Epoch [4/4], Batch[144/1431] loss: 0.005\n",
      "[EFFICIENTNET-cam_pro]. Epoch [4/4], Batch[216/1431] loss: 0.005\n",
      "[EFFICIENTNET-cam_pro]. Epoch [4/4], Batch[288/1431] loss: 0.004\n",
      "[EFFICIENTNET-cam_pro]. Epoch [4/4], Batch[360/1431] loss: 0.005\n",
      "[EFFICIENTNET-cam_pro]. Epoch [4/4], Batch[432/1431] loss: 0.005\n",
      "[EFFICIENTNET-cam_pro]. Epoch [4/4], Batch[504/1431] loss: 0.005\n",
      "[EFFICIENTNET-cam_pro]. Epoch [4/4], Batch[576/1431] loss: 0.005\n",
      "[EFFICIENTNET-cam_pro]. Epoch [4/4], Batch[648/1431] loss: 0.005\n",
      "[EFFICIENTNET-cam_pro]. Epoch [4/4], Batch[720/1431] loss: 0.005\n",
      "[EFFICIENTNET-cam_pro]. Epoch [4/4], Batch[792/1431] loss: 0.005\n",
      "[EFFICIENTNET-cam_pro]. Epoch [4/4], Batch[864/1431] loss: 0.005\n",
      "[EFFICIENTNET-cam_pro]. Epoch [4/4], Batch[936/1431] loss: 0.005\n",
      "[EFFICIENTNET-cam_pro]. Epoch [4/4], Batch[1008/1431] loss: 0.005\n",
      "[EFFICIENTNET-cam_pro]. Epoch [4/4], Batch[1080/1431] loss: 0.005\n",
      "[EFFICIENTNET-cam_pro]. Epoch [4/4], Batch[1152/1431] loss: 0.005\n",
      "[EFFICIENTNET-cam_pro]. Epoch [4/4], Batch[1224/1431] loss: 0.005\n",
      "[EFFICIENTNET-cam_pro]. Epoch [4/4], Batch[1296/1431] loss: 0.005\n",
      "[EFFICIENTNET-cam_pro]. Epoch [4/4], Batch[1368/1431] loss: 0.005\n",
      "train Loss: 0.0050 Acc: 0.9883\n",
      "\n",
      "[EFFICIENTNET-cam_pro]. Epoch [4/4], Batch[143/2862] loss: 0.027\n",
      "[EFFICIENTNET-cam_pro]. Epoch [4/4], Batch[286/2862] loss: 0.049\n",
      "[EFFICIENTNET-cam_pro]. Epoch [4/4], Batch[429/2862] loss: 0.066\n",
      "[EFFICIENTNET-cam_pro]. Epoch [4/4], Batch[572/2862] loss: 0.052\n",
      "[EFFICIENTNET-cam_pro]. Epoch [4/4], Batch[715/2862] loss: 0.050\n",
      "[EFFICIENTNET-cam_pro]. Epoch [4/4], Batch[858/2862] loss: 0.048\n",
      "[EFFICIENTNET-cam_pro]. Epoch [4/4], Batch[1001/2862] loss: 0.044\n",
      "[EFFICIENTNET-cam_pro]. Epoch [4/4], Batch[1144/2862] loss: 0.044\n",
      "[EFFICIENTNET-cam_pro]. Epoch [4/4], Batch[1287/2862] loss: 0.042\n",
      "[EFFICIENTNET-cam_pro]. Epoch [4/4], Batch[1430/2862] loss: 0.038\n",
      "[EFFICIENTNET-cam_pro]. Epoch [4/4], Batch[1573/2862] loss: 0.043\n",
      "[EFFICIENTNET-cam_pro]. Epoch [4/4], Batch[1716/2862] loss: 0.047\n",
      "[EFFICIENTNET-cam_pro]. Epoch [4/4], Batch[1859/2862] loss: 0.051\n",
      "[EFFICIENTNET-cam_pro]. Epoch [4/4], Batch[2002/2862] loss: 0.055\n",
      "[EFFICIENTNET-cam_pro]. Epoch [4/4], Batch[2145/2862] loss: 0.055\n",
      "[EFFICIENTNET-cam_pro]. Epoch [4/4], Batch[2288/2862] loss: 0.053\n",
      "[EFFICIENTNET-cam_pro]. Epoch [4/4], Batch[2431/2862] loss: 0.054\n",
      "[EFFICIENTNET-cam_pro]. Epoch [4/4], Batch[2574/2862] loss: 0.051\n",
      "[EFFICIENTNET-cam_pro]. Epoch [4/4], Batch[2717/2862] loss: 0.055\n",
      "[EFFICIENTNET-cam_pro]. Epoch [4/4], Batch[2860/2862] loss: 0.052\n",
      "[EFFICIENTNET-cam_pro]. Epoch [4/4], Batch[2861/2862] loss: 0.052\n",
      "val Loss: 0.0523 Acc: 0.9790\n",
      "\n",
      "Training complete in 22m 2s\n",
      "Best val Acc: 0.9944 Best val loss: 0.0154\n",
      "model_EFFICIENTNET-cam_pro guardado\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DEVICE:  cuda:0\n",
      "Clases:  ['Benign', 'Pathological']\n",
      "Train image size: 11454\n",
      "Validation image size: 2862\n",
      "Test image size: 7336\n",
      "Dataset loaded.\n",
      "\n",
      "model_vgg-cam loaded\n",
      "[199] loss: 0.063\n",
      "[399] loss: 0.074\n",
      "[599] loss: 0.076\n",
      "[799] loss: 0.075\n",
      "[999] loss: 0.074\n",
      "[1199] loss: 0.076\n",
      "[1399] loss: 0.081\n",
      "[1599] loss: 0.079\n",
      "[1799] loss: 0.074\n",
      "[1999] loss: 0.077\n",
      "[2199] loss: 0.078\n",
      "[2399] loss: 0.077\n",
      "[2599] loss: 0.079\n",
      "[2799] loss: 0.081\n",
      "[2999] loss: 0.080\n",
      "[3199] loss: 0.077\n",
      "[3399] loss: 0.077\n",
      "[3599] loss: 0.076\n",
      "[3799] loss: 0.078\n",
      "[3999] loss: 0.076\n",
      "[4199] loss: 0.077\n",
      "[4399] loss: 0.076\n",
      "[4599] loss: 0.077\n",
      "[4799] loss: 0.079\n",
      "[4999] loss: 0.078\n",
      "[5199] loss: 0.078\n",
      "[5399] loss: 0.078\n",
      "[5599] loss: 0.077\n",
      "[5799] loss: 0.078\n",
      "[5999] loss: 0.077\n",
      "[6199] loss: 0.077\n",
      "[6399] loss: 0.077\n",
      "[6599] loss: 0.076\n",
      "[6799] loss: 0.075\n",
      "[6999] loss: 0.074\n",
      "[7199] loss: 0.073\n",
      "TEST\n",
      " Loss: 0.0734 Acc: 0.9714\n",
      "Testing complete in 0m 42s\n",
      "model_vgg-cam_pro loaded\n",
      "[199] loss: 0.043\n",
      "[399] loss: 0.049\n",
      "[599] loss: 0.051\n",
      "[799] loss: 0.046\n",
      "[999] loss: 0.063\n",
      "[1199] loss: 0.064\n",
      "[1399] loss: 0.073\n",
      "[1599] loss: 0.071\n",
      "[1799] loss: 0.071\n",
      "[1999] loss: 0.074\n",
      "[2199] loss: 0.074\n",
      "[2399] loss: 0.071\n",
      "[2599] loss: 0.072\n",
      "[2799] loss: 0.071\n",
      "[2999] loss: 0.068\n",
      "[3199] loss: 0.068\n",
      "[3399] loss: 0.069\n",
      "[3599] loss: 0.069\n",
      "[3799] loss: 0.070\n",
      "[3999] loss: 0.070\n",
      "[4199] loss: 0.069\n",
      "[4399] loss: 0.069\n",
      "[4599] loss: 0.070\n",
      "[4799] loss: 0.070\n",
      "[4999] loss: 0.071\n",
      "[5199] loss: 0.070\n",
      "[5399] loss: 0.069\n",
      "[5599] loss: 0.069\n",
      "[5799] loss: 0.068\n",
      "[5999] loss: 0.070\n",
      "[6199] loss: 0.070\n",
      "[6399] loss: 0.070\n",
      "[6599] loss: 0.072\n",
      "[6799] loss: 0.071\n",
      "[6999] loss: 0.072\n",
      "[7199] loss: 0.072\n",
      "TEST\n",
      " Loss: 0.0730 Acc: 0.9731\n",
      "Testing complete in 0m 45s\n",
      "model_resnet-cam loaded\n",
      "[199] loss: 0.178\n",
      "[399] loss: 0.218\n",
      "[599] loss: 0.180\n",
      "[799] loss: 0.158\n",
      "[999] loss: 0.197\n",
      "[1199] loss: 0.173\n",
      "[1399] loss: 0.167\n",
      "[1599] loss: 0.173\n",
      "[1799] loss: 0.175\n",
      "[1999] loss: 0.180\n",
      "[2199] loss: 0.184\n",
      "[2399] loss: 0.180\n",
      "[2599] loss: 0.179\n",
      "[2799] loss: 0.175\n",
      "[2999] loss: 0.182\n",
      "[3199] loss: 0.176\n",
      "[3399] loss: 0.169\n",
      "[3599] loss: 0.172\n",
      "[3799] loss: 0.168\n",
      "[3999] loss: 0.168\n",
      "[4199] loss: 0.166\n",
      "[4399] loss: 0.163\n",
      "[4599] loss: 0.161\n",
      "[4799] loss: 0.159\n",
      "[4999] loss: 0.156\n",
      "[5199] loss: 0.152\n",
      "[5399] loss: 0.153\n",
      "[5599] loss: 0.153\n",
      "[5799] loss: 0.152\n",
      "[5999] loss: 0.157\n",
      "[6199] loss: 0.157\n",
      "[6399] loss: 0.162\n",
      "[6599] loss: 0.167\n",
      "[6799] loss: 0.166\n",
      "[6999] loss: 0.163\n",
      "[7199] loss: 0.162\n",
      "TEST\n",
      " Loss: 0.1599 Acc: 0.9656\n",
      "Testing complete in 0m 39s\n",
      "model_resnet-cam_pro loaded\n",
      "[199] loss: 0.142\n",
      "[399] loss: 0.145\n",
      "[599] loss: 0.181\n",
      "[799] loss: 0.166\n",
      "[999] loss: 0.147\n",
      "[1199] loss: 0.158\n",
      "[1399] loss: 0.146\n",
      "[1599] loss: 0.151\n",
      "[1799] loss: 0.144\n",
      "[1999] loss: 0.137\n",
      "[2199] loss: 0.139\n",
      "[2399] loss: 0.141\n",
      "[2599] loss: 0.138\n",
      "[2799] loss: 0.156\n",
      "[2999] loss: 0.155\n",
      "[3199] loss: 0.158\n",
      "[3399] loss: 0.159\n",
      "[3599] loss: 0.155\n",
      "[3799] loss: 0.153\n",
      "[3999] loss: 0.149\n",
      "[4199] loss: 0.144\n",
      "[4399] loss: 0.143\n",
      "[4599] loss: 0.144\n",
      "[4799] loss: 0.142\n",
      "[4999] loss: 0.142\n",
      "[5199] loss: 0.140\n",
      "[5399] loss: 0.138\n",
      "[5599] loss: 0.142\n",
      "[5799] loss: 0.145\n",
      "[5999] loss: 0.145\n",
      "[6199] loss: 0.148\n",
      "[6399] loss: 0.146\n",
      "[6599] loss: 0.144\n",
      "[6799] loss: 0.143\n",
      "[6999] loss: 0.143\n",
      "[7199] loss: 0.141\n",
      "TEST\n",
      " Loss: 0.1430 Acc: 0.9618\n",
      "Testing complete in 0m 37s\n",
      "model_mobilenet-cam loaded\n",
      "[199] loss: 0.191\n",
      "[399] loss: 0.203\n",
      "[599] loss: 0.153\n",
      "[799] loss: 0.147\n",
      "[999] loss: 0.139\n",
      "[1199] loss: 0.135\n",
      "[1399] loss: 0.127\n",
      "[1599] loss: 0.127\n",
      "[1799] loss: 0.117\n",
      "[1999] loss: 0.132\n",
      "[2199] loss: 0.126\n",
      "[2399] loss: 0.136\n",
      "[2599] loss: 0.134\n",
      "[2799] loss: 0.129\n",
      "[2999] loss: 0.127\n",
      "[3199] loss: 0.127\n",
      "[3399] loss: 0.126\n",
      "[3599] loss: 0.127\n",
      "[3799] loss: 0.128\n",
      "[3999] loss: 0.130\n",
      "[4199] loss: 0.130\n",
      "[4399] loss: 0.129\n",
      "[4599] loss: 0.133\n",
      "[4799] loss: 0.129\n",
      "[4999] loss: 0.131\n",
      "[5199] loss: 0.131\n",
      "[5399] loss: 0.129\n",
      "[5599] loss: 0.127\n",
      "[5799] loss: 0.126\n",
      "[5999] loss: 0.129\n",
      "[6199] loss: 0.128\n",
      "[6399] loss: 0.128\n",
      "[6599] loss: 0.127\n",
      "[6799] loss: 0.125\n",
      "[6999] loss: 0.129\n",
      "[7199] loss: 0.127\n",
      "TEST\n",
      " Loss: 0.1264 Acc: 0.9684\n",
      "Testing complete in 0m 58s\n",
      "model_mobilenet-cam_pro loaded\n",
      "[199] loss: 0.020\n",
      "[399] loss: 0.022\n",
      "[599] loss: 0.029\n",
      "[799] loss: 0.038\n",
      "[999] loss: 0.038\n",
      "[1199] loss: 0.044\n",
      "[1399] loss: 0.053\n",
      "[1599] loss: 0.063\n",
      "[1799] loss: 0.060\n",
      "[1999] loss: 0.058\n",
      "[2199] loss: 0.057\n",
      "[2399] loss: 0.057\n",
      "[2599] loss: 0.055\n",
      "[2799] loss: 0.060\n",
      "[2999] loss: 0.056\n",
      "[3199] loss: 0.055\n",
      "[3399] loss: 0.058\n",
      "[3599] loss: 0.056\n",
      "[3799] loss: 0.055\n",
      "[3999] loss: 0.057\n",
      "[4199] loss: 0.055\n",
      "[4399] loss: 0.054\n",
      "[4599] loss: 0.053\n",
      "[4799] loss: 0.052\n",
      "[4999] loss: 0.052\n",
      "[5199] loss: 0.051\n",
      "[5399] loss: 0.051\n",
      "[5599] loss: 0.051\n",
      "[5799] loss: 0.052\n",
      "[5999] loss: 0.053\n",
      "[6199] loss: 0.051\n",
      "[6399] loss: 0.050\n",
      "[6599] loss: 0.051\n",
      "[6799] loss: 0.050\n",
      "[6999] loss: 0.050\n",
      "[7199] loss: 0.050\n",
      "TEST\n",
      " Loss: 0.0494 Acc: 0.9846\n",
      "Testing complete in 0m 59s\n",
      "model_efficientnet-cam loaded\n",
      "[199] loss: 0.081\n",
      "[399] loss: 0.073\n",
      "[599] loss: 0.088\n",
      "[799] loss: 0.101\n",
      "[999] loss: 0.120\n",
      "[1199] loss: 0.124\n",
      "[1399] loss: 0.127\n",
      "[1599] loss: 0.127\n",
      "[1799] loss: 0.122\n",
      "[1999] loss: 0.123\n",
      "[2199] loss: 0.120\n",
      "[2399] loss: 0.120\n",
      "[2599] loss: 0.120\n",
      "[2799] loss: 0.122\n",
      "[2999] loss: 0.119\n",
      "[3199] loss: 0.117\n",
      "[3399] loss: 0.114\n",
      "[3599] loss: 0.115\n",
      "[3799] loss: 0.113\n",
      "[3999] loss: 0.113\n",
      "[4199] loss: 0.112\n",
      "[4399] loss: 0.113\n",
      "[4599] loss: 0.113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4799] loss: 0.113\n",
      "[4999] loss: 0.113\n",
      "[5199] loss: 0.115\n",
      "[5399] loss: 0.119\n",
      "[5599] loss: 0.121\n",
      "[5799] loss: 0.119\n",
      "[5999] loss: 0.119\n",
      "[6199] loss: 0.123\n",
      "[6399] loss: 0.124\n",
      "[6599] loss: 0.122\n",
      "[6799] loss: 0.124\n",
      "[6999] loss: 0.125\n",
      "[7199] loss: 0.123\n",
      "TEST\n",
      " Loss: 0.1220 Acc: 0.9561\n",
      "Testing complete in 1m 19s\n",
      "model_efficientnet-cam_pro loaded\n",
      "[199] loss: 0.118\n",
      "[399] loss: 0.131\n",
      "[599] loss: 0.155\n",
      "[799] loss: 0.175\n",
      "[999] loss: 0.171\n",
      "[1199] loss: 0.187\n",
      "[1399] loss: 0.177\n",
      "[1599] loss: 0.183\n",
      "[1799] loss: 0.179\n",
      "[1999] loss: 0.174\n",
      "[2199] loss: 0.169\n",
      "[2399] loss: 0.176\n",
      "[2599] loss: 0.187\n",
      "[2799] loss: 0.191\n",
      "[2999] loss: 0.191\n",
      "[3199] loss: 0.185\n",
      "[3399] loss: 0.189\n",
      "[3599] loss: 0.188\n",
      "[3799] loss: 0.183\n",
      "[3999] loss: 0.182\n",
      "[4199] loss: 0.182\n",
      "[4399] loss: 0.180\n",
      "[4599] loss: 0.187\n",
      "[4799] loss: 0.187\n",
      "[4999] loss: 0.184\n",
      "[5199] loss: 0.180\n",
      "[5399] loss: 0.180\n",
      "[5599] loss: 0.179\n",
      "[5799] loss: 0.179\n",
      "[5999] loss: 0.178\n",
      "[6199] loss: 0.177\n",
      "[6399] loss: 0.178\n",
      "[6599] loss: 0.178\n",
      "[6799] loss: 0.180\n",
      "[6999] loss: 0.181\n",
      "[7199] loss: 0.182\n",
      "TEST\n",
      " Loss: 0.1817 Acc: 0.9408\n",
      "Testing complete in 1m 23s\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "DEVICE:  cuda\n",
      "Clases:  ['Benign', 'Pathological']\n",
      "Train image size: 11454\n",
      "Validation image size: 2862\n",
      "Test image size: 7336\n",
      "Dataset loaded.\n",
      "\n",
      "model_vgg-cam loaded\n",
      "técnica:  cam\n",
      "LONGITUD DEL HEATMAPS:  447\n",
      "Mejor valor: 0.610\n",
      " con el umbral: 0.0000\n",
      "Área bajo la curva: 0.4623479298516506\n",
      "model_vgg-cam_pro loaded\n",
      "técnica:  gradcam\n",
      "LONGITUD DEL HEATMAPS:  447\n",
      "Mejor valor: 0.661\n",
      " con el umbral: 0.1000\n",
      "Área bajo la curva: 0.4221878616742945\n",
      "técnica:  gradcampp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x0000021444A39D30>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1358, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1322, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\popen_spawn_win32.py\", line 108, in wait\n",
      "    res = _winapi.WaitForSingleObject(int(self._handle), msecs)\n",
      "KeyboardInterrupt: \n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3444, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\pedro\\AppData\\Local\\Temp/ipykernel_38212/2058668793.py\", line 77, in <module>\n",
      "    run()\n",
      "  File \"C:\\Users\\pedro\\AppData\\Local\\Temp/ipykernel_38212/2058668793.py\", line 46, in run\n",
      "    informacion_umbral_mascaras(path_guardado_modelos, path_dataset, device='cuda')\n",
      "  File \"C:\\Users\\pedro\\Documents\\TFG\\TFG\\src\\utils.py\", line 728, in informacion_umbral_mascaras\n",
      "    iou_medios, maximo_representativo, mejor_umbral = curvas_umbral_mascara(models_dic[f'{modelo_base}-{name}']['model'],\n",
      "  File \"C:\\Users\\pedro\\Documents\\TFG\\TFG\\src\\utils.py\", line 610, in curvas_umbral_mascara\n",
      "    heatmaps.append(model.saliency_map(inp,\n",
      "  File \"C:\\Users\\pedro\\Documents\\TFG\\TFG\\src\\CAM\\cam_abstract.py\", line 117, in saliency_map\n",
      "    activations = self.get_activations(x)\n",
      "  File \"C:\\Users\\pedro\\Documents\\TFG\\TFG\\src\\CAM\\cam.py\", line 127, in get_activations\n",
      "    x_mod = mod(x_mod)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1110, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\", line 141, in forward\n",
      "    input = module(input)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\", line 1110, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\", line 447, in forward\n",
      "    return self._conv_forward(input, self.weight, self.bias)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\", line 443, in _conv_forward\n",
      "    return F.conv2d(input, weight, bias, self.stride,\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2064, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 1541, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 1499, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 709, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 755, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\ntpath.py\", line 664, in realpath\n",
      "    if _getfinalpathname(spath) == path:\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_38212/2058668793.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_38212/2058668793.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m()\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m     \u001b[0minformacion_umbral_mascaras\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_guardado_modelos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cuda'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\TFG\\TFG\\src\\utils.py\u001b[0m in \u001b[0;36minformacion_umbral_mascaras\u001b[1;34m(path_modelos, path_dataset, cam, cam_pro, device)\u001b[0m\n\u001b[0;32m    727\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mt_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtechnique\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtechnics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m                 iou_medios, maximo_representativo, mejor_umbral = curvas_umbral_mascara(models_dic[f'{modelo_base}-{name}']['model'], \n\u001b[0m\u001b[0;32m    729\u001b[0m                                                                                         \u001b[0mtechnique\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\TFG\\TFG\\src\\utils.py\u001b[0m in \u001b[0;36mcurvas_umbral_mascara\u001b[1;34m(model, technique, dataloader_val, alpha, device)\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m         heatmaps.append(model.saliency_map(inp,\n\u001b[0m\u001b[0;32m    611\u001b[0m                                             \u001b[0mtechnique\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\TFG\\TFG\\src\\CAM\\cam_abstract.py\u001b[0m in \u001b[0;36msaliency_map\u001b[1;34m(self, x, technique, n_noise, std, device)\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;31m# We generate the activation map\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m         \u001b[0mactivations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_activations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\TFG\\TFG\\src\\CAM\\cam.py\u001b[0m in \u001b[0;36mget_activations\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmod\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m             \u001b[0mx_mod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_mod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    446\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 447\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    448\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    442\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m--> 443\u001b[1;33m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[0;32m    444\u001b[0m                         self.padding, self.dilation, self.groups)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2063\u001b[0m                         \u001b[1;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2064\u001b[1;33m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2065\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2064\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2065\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2066\u001b[1;33m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[0;32m   2067\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[0;32m   2068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1365\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1367\u001b[1;33m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0;32m   1369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1265\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1266\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1267\u001b[1;33m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1269\u001b[0m             )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1122\u001b[0m         \u001b[1;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1124\u001b[1;33m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[0;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[0;32m   1126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1082\u001b[1;33m         \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[1;34m(etype, value, records)\u001b[0m\n\u001b[0;32m    380\u001b[0m     \u001b[1;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m     \u001b[1;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function flush_figures at 0x0000021447F9A310> (for post_execute):\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\events.py\", line 89, in trigger\n",
      "    func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib_inline\\backend_inline.py\", line 121, in flush_figures\n",
      "    return show(True)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib_inline\\backend_inline.py\", line 41, in show\n",
      "    display(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\display.py\", line 320, in display\n",
      "    format_dict, md_dict = format(obj, include=include, exclude=exclude)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py\", line 180, in format\n",
      "    data = formatter(obj)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\decorator.py\", line 232, in fun\n",
      "    return caller(func, *(extras + args), **kw)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py\", line 224, in catch_format_error\n",
      "    r = method(self, *args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py\", line 341, in __call__\n",
      "    return printer(obj)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\pylabtools.py\", line 151, in print_figure\n",
      "    fig.canvas.print_figure(bytes_io, **kw)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backend_bases.py\", line 2230, in print_figure\n",
      "    self.figure.draw(renderer)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\artist.py\", line 74, in draw_wrapper\n",
      "    result = draw(artist, renderer, *args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\artist.py\", line 51, in draw_wrapper\n",
      "    return draw(artist, renderer, *args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py\", line 2790, in draw\n",
      "    mimage._draw_list_compositing_images(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\image.py\", line 132, in _draw_list_compositing_images\n",
      "    a.draw(renderer)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\artist.py\", line 51, in draw_wrapper\n",
      "    return draw(artist, renderer, *args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\_api\\deprecation.py\", line 431, in wrapper\n",
      "    return func(*inner_args, **inner_kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\", line 2921, in draw\n",
      "    mimage._draw_list_compositing_images(renderer, self, artists)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\image.py\", line 132, in _draw_list_compositing_images\n",
      "    a.draw(renderer)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\artist.py\", line 51, in draw_wrapper\n",
      "    return draw(artist, renderer, *args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\axis.py\", line 1146, in draw\n",
      "    tick.draw(renderer)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\artist.py\", line 51, in draw_wrapper\n",
      "    return draw(artist, renderer, *args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\axis.py\", line 302, in draw\n",
      "    artist.draw(renderer)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\artist.py\", line 51, in draw_wrapper\n",
      "    return draw(artist, renderer, *args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\lines.py\", line 848, in draw\n",
      "    if isinstance(snap, Real):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\abc.py\", line 119, in __instancecheck__\n",
      "    return _abc_instancecheck(cls, instance)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2064, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 1541, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 1503, in getframeinfo\n",
      "    lines, lnum = findsource(frame)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 170, in findsource\n",
      "    file = getsourcefile(object) or getfile(object)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 706, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Reset CUDA cache\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "path_guardado_modelos = '..\\\\..\\\\modelos_entrenados\\\\'\n",
    "path_dataset = r'..\\..\\SICAPv1\\224_patch_par'\n",
    "def run():\n",
    "    # List of technics to train\n",
    "    model_classes = ['cam', 'cam_pro']\n",
    "    technics_pro = ['gradcam', 'gradcampp', 'smoothgradcampp']\n",
    "    \n",
    "    models_base = { 'VGG': {'model':models.vgg16(pretrained=True),\n",
    "                            'input_size': 224},\n",
    "                    'RESNET': {'model':models.resnet18(pretrained=True),\n",
    "                               'input_size': 224},\n",
    "                    'MOBILENET': {'model':models.mobilenet_v2(pretrained=True),\n",
    "                                  'input_size': 224},\n",
    "                    'EFFICIENTNET': {'model':torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', \n",
    "                                                            'nvidia_efficientnet_b0', \n",
    "                                                            pretrained=True),\n",
    "                                  'input_size': 224},\n",
    "                   }\n",
    "    \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print('DEVICE: ', device)\n",
    "\n",
    "    # Read datasets\n",
    "    dataloaders, dataset_sizes = load_data(path_dataset)\n",
    "    print('\\n\\n\\n\\n')\n",
    "\n",
    "    \n",
    "    \n",
    "    # Entrenamos\n",
    "    train_cam_models(path_modelos=path_guardado_modelos,\n",
    "                     path_dataset=path_dataset,\n",
    "                     epochs=100,\n",
    "                     early_stopping=10,\n",
    "                     device = device)\n",
    "    print('\\n\\n\\n\\n')\n",
    "    \n",
    "    \n",
    "    # Testeamos \n",
    "    test_cam_models(path_guardado_modelos, path_dataset)\n",
    "    print('\\n\\n\\n\\n')\n",
    "    \n",
    "\n",
    "    informacion_umbral_mascaras(path_guardado_modelos, path_dataset, device='cuda')\n",
    "    \n",
    "\n",
    "    iter_dataloader = iter(dataloaders['val'])\n",
    "    for i in range(10):\n",
    "        # Cogemos la activación de las capas\n",
    "        x, mask, act_classes=next(iter_dataloader)\n",
    "\n",
    "        while act_classes[0]!=1:\n",
    "            x, mask, act_classes=next(iter_dataloader)\n",
    "\n",
    "        x=x.to(device)\n",
    "        act_classes=act_classes.to(device)\n",
    "\n",
    "        for net in models_base.keys():\n",
    "            plot_grid(x,\n",
    "                      mask,\n",
    "                      act_classes,\n",
    "                      net,\n",
    "                      n_noise=10,\n",
    "                      std=0.2,\n",
    "                      cam=True,\n",
    "                      gradcam=True,\n",
    "                      gradcampp=True,\n",
    "                      smoothgradcampp=True,\n",
    "                      device=device,\n",
    "                      path_modelos=path_guardado_modelos)\n",
    "            \n",
    "            print('='*50)\n",
    "\n",
    "\n",
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4993d18",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_38212/1554102346.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_xticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_yticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mshow\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    376\u001b[0m     \"\"\"\n\u001b[0;32m    377\u001b[0m     \u001b[0m_warn_if_gui_out_of_main_thread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 378\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_backend_mod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    379\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib_inline\\backend_inline.py\u001b[0m in \u001b[0;36mshow\u001b[1;34m(close, block)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfigure_manager\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mGcf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_all_fig_managers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m             display(\n\u001b[0m\u001b[0;32m     42\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m                 \u001b[0mmetadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\display.py\u001b[0m in \u001b[0;36mdisplay\u001b[1;34m(include, exclude, metadata, transient, display_id, *objs, **kwargs)\u001b[0m\n\u001b[0;32m    318\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m             \u001b[0mformat_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    321\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m                 \u001b[1;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36mformat\u001b[1;34m(self, obj, include, exclude)\u001b[0m\n\u001b[0;32m    178\u001b[0m             \u001b[0mmd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m             \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m                 \u001b[1;31m# FIXME: log the exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\decorator.py\u001b[0m in \u001b[0;36mfun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mkwsyntax\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mcaller\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextras\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m     \u001b[0mfun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[0mfun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[1;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[1;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m         \u001b[1;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    339\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 341\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    342\u001b[0m             \u001b[1;31m# Finally look for special method names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[1;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m         \u001b[0mFigureCanvasBase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m     \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'svg'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[0;32m   2232\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2233\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"tight\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2234\u001b[1;33m                     bbox_inches = self.figure.get_tightbbox(\n\u001b[0m\u001b[0;32m   2235\u001b[0m                         renderer, bbox_extra_artists=bbox_extra_artists)\n\u001b[0;32m   2236\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mpad_inches\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py\u001b[0m in \u001b[0;36mget_tightbbox\u001b[1;34m(self, renderer, bbox_extra_artists)\u001b[0m\n\u001b[0;32m   1646\u001b[0m                 \u001b[1;31m# need this conditional....\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1647\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1648\u001b[1;33m                     bbox = ax.get_tightbbox(\n\u001b[0m\u001b[0;32m   1649\u001b[0m                         renderer, bbox_extra_artists=bbox_extra_artists)\n\u001b[0;32m   1650\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36mget_tightbbox\u001b[1;34m(self, renderer, call_axes_locator, bbox_extra_artists, for_layout_only)\u001b[0m\n\u001b[0;32m   4475\u001b[0m                     \u001b[1;31m# this artist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4476\u001b[0m                     \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4477\u001b[1;33m             \u001b[0mbbox\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_tightbbox\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4478\u001b[0m             if (bbox is not None\n\u001b[0;32m   4479\u001b[0m                     \u001b[1;32mand\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mbbox\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwidth\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mget_tightbbox\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0menclosing\u001b[0m \u001b[0mbounding\u001b[0m \u001b[0mbox\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32min\u001b[0m \u001b[0mfigure\u001b[0m \u001b[0mpixel\u001b[0m \u001b[0mcoordinates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m         \"\"\"\n\u001b[1;32m--> 306\u001b[1;33m         \u001b[0mbbox\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_window_extent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    307\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_clip_on\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m             \u001b[0mclip_box\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_clip_box\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\patches.py\u001b[0m in \u001b[0;36mget_window_extent\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_window_extent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 621\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_extents\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    622\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    623\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_convert_xy_units\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\path.py\u001b[0m in \u001b[0;36mget_extents\u001b[1;34m(self, transform, **kwargs)\u001b[0m\n\u001b[0;32m    615\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBbox\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 617\u001b[1;33m             \u001b[0mself\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    618\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcodes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m             \u001b[0mxys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvertices\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\transforms.py\u001b[0m in \u001b[0;36mtransform_path\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m   1573\u001b[0m         \u001b[0mthat\u001b[0m \u001b[0mbegan\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mline\u001b[0m \u001b[0msegments\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1574\u001b[0m         \"\"\"\n\u001b[1;32m-> 1575\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform_path_affine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform_path_non_affine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1577\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtransform_path_affine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\transforms.py\u001b[0m in \u001b[0;36mtransform_path_affine\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m   1583\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtransform_path_affine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransform_path_non_affine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1584\u001b[0m         \"\"\"\n\u001b[1;32m-> 1585\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_affine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform_path_affine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1587\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtransform_path_non_affine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\transforms.py\u001b[0m in \u001b[0;36mget_affine\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2405\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2406\u001b[0m             return Affine2D(np.dot(self._b.get_affine().get_matrix(),\n\u001b[1;32m-> 2407\u001b[1;33m                                    self._a.get_affine().get_matrix()))\n\u001b[0m\u001b[0;32m   2408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2409\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minverted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\transforms.py\u001b[0m in \u001b[0;36mget_affine\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2404\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_b\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_affine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2405\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2406\u001b[1;33m             return Affine2D(np.dot(self._b.get_affine().get_matrix(),\n\u001b[0m\u001b[0;32m   2407\u001b[0m                                    self._a.get_affine().get_matrix()))\n\u001b[0;32m   2408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\transforms.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, matrix, **kwargs)\u001b[0m\n\u001b[0;32m   1879\u001b[0m             \u001b[1;31m# A bit faster than np.identity(3).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1880\u001b[0m             \u001b[0mmatrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mIdentityTransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mtx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1881\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mtx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1882\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_invalid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2,ncols=4,figsize=(20,10))\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(4):\n",
    "        if i==0 or j==0:\n",
    "            axes[i,j].title.set_text(\"Holddddddddddddddddda\\n\"*(j+1))\n",
    "        axes[i,j].imshow(np.random.rand(224,224,3),  cmap=plt.get_cmap('turbo'))\n",
    "        axes[i,j].imshow(np.ones((224,224)), alpha=0.5)\n",
    "        \n",
    "        axes[i,j].set_xticks([])\n",
    "        axes[i,j].set_yticks([])\n",
    "plt.show()  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e230d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def holi(num):\n",
    "    lista=[]\n",
    "\n",
    "    print('#'*1000)\n",
    "    for i in range(num):\n",
    "        lista.append(torch.ones((200,1000)).to('cuda'))\n",
    "\n",
    "        t = torch.cuda.get_device_properties(0).total_memory\n",
    "        r = torch.cuda.memory_reserved(0)\n",
    "        a = torch.cuda.memory_allocated(0)\n",
    "        f = r-a  # free inside reserved\n",
    "\n",
    "        print(f'total    : {t}')\n",
    "        print(f'used     : {a}')\n",
    "        print(f'free    : {f}\\n\\n')\n",
    "        \n",
    "    #lista = []\n",
    "        \n",
    "for i in range(100):\n",
    "    holi(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce692185",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t = torch.cuda.get_device_properties(0).total_memory\n",
    "r = torch.cuda.memory_reserved(0)\n",
    "a = torch.cuda.memory_allocated(0)\n",
    "f = r-a  # free inside reserved\n",
    "\n",
    "print(f'total    : {t}')\n",
    "print(f'used     : {a}')\n",
    "print(f'free    : {f}\\n\\n')\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb27a930",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1.,1.,1.],[2.,2.,2.],[10.,10.,10.]])\n",
    "\n",
    "print(isinstance(a,np.ndarray))\n",
    "print(a.sum())\n",
    "print(a.sum(axis=0))\n",
    "print(a.sum(axis=1))\n",
    "print(a.sum(axis=(0,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c20d5ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99290656",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
