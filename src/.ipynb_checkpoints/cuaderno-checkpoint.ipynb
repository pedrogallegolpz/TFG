{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "187defad",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE:  cuda:0\n",
      "Clases:  ['Benign', 'Pathological']\n",
      "Train image size: 6366\n",
      "Validation image size: 1591\n",
      "Test image size: 4158\n",
      "Dataset loaded.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "model_cam loaded\n",
      "model_gradcam loaded\n",
      "model_gradcampp loaded\n",
      "model_smoothgradcampp loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pedro\\Documents\\TFG\\TFG\\src\\CAM\\cam_abstract.py:112: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matricesor `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at  C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\TensorShape.cpp:2318.)\n",
      "  activations_final = relu(((parameters[class_i]*activations.T).T).sum(axis=0))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yprob tensor([[1.0000e+00, 3.5360e-06]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "PROB CAM:\n",
      "\t- SANO: 1.00000\n",
      "\t- CANCER: 0.00000\n",
      "(CLASS PREDICTED -- sano) vs (sano -- ACTUAL CLASS)\n",
      "y tensor([0, 0], device='cuda:0')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8880/2655402590.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[0mact_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mact_classes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m         \u001b[0mmodels_dic\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34mf'{name}'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_saliency_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mact_classes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"#\"\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m70\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\TFG\\TFG\\src\\CAM\\cam_abstract.py\u001b[0m in \u001b[0;36mplot_saliency_map\u001b[1;34m(self, x, y, class_plot, n_noise, std, device)\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_mod_new\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mclass_plot\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mclass_plot\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred_mod_new\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mclass_plot\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    177\u001b[0m                 \u001b[0mplot_hm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "from torch.nn.modules.pooling import AdaptiveAvgPool2d\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "import torchvision.models as models\n",
    "import torchvision\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import math\n",
    "\n",
    "import cv2\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import abc  # For implementing abstract methods\n",
    "\n",
    "import CAM.cam\n",
    "from utils import load_model, load_data, train_cam_models, test_cam_models\n",
    "import json\n",
    "import math\n",
    "from torchvision.transforms import Resize\n",
    "# Reset CUDA cache\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "path_guardado_modelos = 'modelos/'\n",
    "\n",
    "# List of technics to train\n",
    "technics = ['cam','gradcam', 'gradcampp', 'smoothgradcampp']\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('DEVICE: ', device)\n",
    "\n",
    "# Read datasets\n",
    "dataloaders, dataset_sizes = load_data(r'..\\..\\SICAPv1\\299_patch_impar')\n",
    "print('\\n\\n\\n\\n')\n",
    "\n",
    "\"\"\"\n",
    "# Entrenamos\n",
    "train_cam_models(path_guardado_modelos, epochs=10)\n",
    "print('\\n\\n\\n\\n')\n",
    "\n",
    "# Testeamos \n",
    "test_cam_models(path_guardado_modelos)\n",
    "print('\\n\\n\\n\\n')\n",
    "\"\"\"\n",
    "\n",
    "models_dic = {}\n",
    "for name in technics:\n",
    "    # Load model\n",
    "    models_dic[f'{name}'] = load_model(path_guardado_modelos, name, device)\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    # Cogemos la activaci√≥n de las capas\n",
    "    x, act_classes=next(iter(dataloaders['test']))\n",
    "    x=x.to(device)\n",
    "    for name in technics:\n",
    "        act_classes=act_classes.to(device)\n",
    "\n",
    "        models_dic[f'{name}']['model'].plot_saliency_map(x, act_classes[0], -1)\n",
    "\n",
    "        print(\"#\"*70)\n",
    "        print(\"#\"*70)\n",
    "        print(\"#\"*70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4993d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[-9.,2.,1.]])\n",
    "\n",
    "print(torch.argmax(a, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bb88b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
